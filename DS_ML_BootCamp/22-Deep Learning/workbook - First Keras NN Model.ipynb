{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "floppy-formation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "vietnamese-better",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('DATA/fake_reg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "surprised-trustee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>461.527929</td>\n",
       "      <td>999.787558</td>\n",
       "      <td>999.766096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>548.130011</td>\n",
       "      <td>998.861615</td>\n",
       "      <td>1001.042403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>410.297162</td>\n",
       "      <td>1000.070267</td>\n",
       "      <td>998.844015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>540.382220</td>\n",
       "      <td>999.952251</td>\n",
       "      <td>1000.440940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>546.024553</td>\n",
       "      <td>1000.446011</td>\n",
       "      <td>1000.338531</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        price     feature1     feature2\n",
       "0  461.527929   999.787558   999.766096\n",
       "1  548.130011   998.861615  1001.042403\n",
       "2  410.297162  1000.070267   998.844015\n",
       "3  540.382220   999.952251  1000.440940\n",
       "4  546.024553  1000.446011  1000.338531"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "continuous-superintendent",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   price     1000 non-null   float64\n",
      " 1   feature1  1000 non-null   float64\n",
      " 2   feature2  1000 non-null   float64\n",
      "dtypes: float64(3)\n",
      "memory usage: 23.6 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "funded-yield",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>498.673029</td>\n",
       "      <td>1000.014171</td>\n",
       "      <td>999.979847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>93.785431</td>\n",
       "      <td>0.974018</td>\n",
       "      <td>0.948330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>223.346793</td>\n",
       "      <td>997.058347</td>\n",
       "      <td>996.995651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>433.025732</td>\n",
       "      <td>999.332068</td>\n",
       "      <td>999.316106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>502.382117</td>\n",
       "      <td>1000.009915</td>\n",
       "      <td>1000.002243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>564.921588</td>\n",
       "      <td>1000.637580</td>\n",
       "      <td>1000.645380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>774.407854</td>\n",
       "      <td>1003.207934</td>\n",
       "      <td>1002.666308</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             price     feature1     feature2\n",
       "count  1000.000000  1000.000000  1000.000000\n",
       "mean    498.673029  1000.014171   999.979847\n",
       "std      93.785431     0.974018     0.948330\n",
       "min     223.346793   997.058347   996.995651\n",
       "25%     433.025732   999.332068   999.316106\n",
       "50%     502.382117  1000.009915  1000.002243\n",
       "75%     564.921588  1000.637580  1000.645380\n",
       "max     774.407854  1003.207934  1002.666308"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "behind-mason",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.PairGrid at 0x21f1c9a14e0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 540x540 with 12 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.pairplot(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "decimal-curtis",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fake data so we can see that feature2 correlates strongly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "double-uganda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "excessive-immunology",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['feature1','feature2']].values #.values makes it a NP array for TF\n",
    "y = df['price'].values\n",
    "#NP arrays\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "laden-shelter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 999.78755752,  999.7660962 ],\n",
       "       [ 998.86161491, 1001.04240315],\n",
       "       [1000.07026691,  998.84401463],\n",
       "       ...,\n",
       "       [1001.45164617,  998.84760554],\n",
       "       [1000.77102275,  998.56285086],\n",
       "       [ 999.2322436 , 1001.45140713]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "compatible-excellence",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "caring-surrey",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(700, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ready-illinois",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "legendary-router",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "surprising-wiring",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class MinMaxScaler in module sklearn.preprocessing._data:\n",
      "\n",
      "class MinMaxScaler(sklearn.base.TransformerMixin, sklearn.base.BaseEstimator)\n",
      " |  MinMaxScaler(feature_range=(0, 1), *, copy=True, clip=False)\n",
      " |  \n",
      " |  Transform features by scaling each feature to a given range.\n",
      " |  \n",
      " |  This estimator scales and translates each feature individually such\n",
      " |  that it is in the given range on the training set, e.g. between\n",
      " |  zero and one.\n",
      " |  \n",
      " |  The transformation is given by::\n",
      " |  \n",
      " |      X_std = (X - X.min(axis=0)) / (X.max(axis=0) - X.min(axis=0))\n",
      " |      X_scaled = X_std * (max - min) + min\n",
      " |  \n",
      " |  where min, max = feature_range.\n",
      " |  \n",
      " |  This transformation is often used as an alternative to zero mean,\n",
      " |  unit variance scaling.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <preprocessing_scaler>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  feature_range : tuple (min, max), default=(0, 1)\n",
      " |      Desired range of transformed data.\n",
      " |  \n",
      " |  copy : bool, default=True\n",
      " |      Set to False to perform inplace row normalization and avoid a\n",
      " |      copy (if the input is already a numpy array).\n",
      " |  \n",
      " |  clip: bool, default=False\n",
      " |      Set to True to clip transformed values of held-out data to\n",
      " |      provided `feature range`.\n",
      " |  \n",
      " |      .. versionadded:: 0.24\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  min_ : ndarray of shape (n_features,)\n",
      " |      Per feature adjustment for minimum. Equivalent to\n",
      " |      ``min - X.min(axis=0) * self.scale_``\n",
      " |  \n",
      " |  scale_ : ndarray of shape (n_features,)\n",
      " |      Per feature relative scaling of the data. Equivalent to\n",
      " |      ``(max - min) / (X.max(axis=0) - X.min(axis=0))``\n",
      " |  \n",
      " |      .. versionadded:: 0.17\n",
      " |         *scale_* attribute.\n",
      " |  \n",
      " |  data_min_ : ndarray of shape (n_features,)\n",
      " |      Per feature minimum seen in the data\n",
      " |  \n",
      " |      .. versionadded:: 0.17\n",
      " |         *data_min_*\n",
      " |  \n",
      " |  data_max_ : ndarray of shape (n_features,)\n",
      " |      Per feature maximum seen in the data\n",
      " |  \n",
      " |      .. versionadded:: 0.17\n",
      " |         *data_max_*\n",
      " |  \n",
      " |  data_range_ : ndarray of shape (n_features,)\n",
      " |      Per feature range ``(data_max_ - data_min_)`` seen in the data\n",
      " |  \n",
      " |      .. versionadded:: 0.17\n",
      " |         *data_range_*\n",
      " |  \n",
      " |  n_samples_seen_ : int\n",
      " |      The number of samples processed by the estimator.\n",
      " |      It will be reset on new calls to fit, but increments across\n",
      " |      ``partial_fit`` calls.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from sklearn.preprocessing import MinMaxScaler\n",
      " |  >>> data = [[-1, 2], [-0.5, 6], [0, 10], [1, 18]]\n",
      " |  >>> scaler = MinMaxScaler()\n",
      " |  >>> print(scaler.fit(data))\n",
      " |  MinMaxScaler()\n",
      " |  >>> print(scaler.data_max_)\n",
      " |  [ 1. 18.]\n",
      " |  >>> print(scaler.transform(data))\n",
      " |  [[0.   0.  ]\n",
      " |   [0.25 0.25]\n",
      " |   [0.5  0.5 ]\n",
      " |   [1.   1.  ]]\n",
      " |  >>> print(scaler.transform([[2, 2]]))\n",
      " |  [[1.5 0. ]]\n",
      " |  \n",
      " |  See Also\n",
      " |  --------\n",
      " |  minmax_scale : Equivalent function without the estimator API.\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  NaNs are treated as missing values: disregarded in fit, and maintained in\n",
      " |  transform.\n",
      " |  \n",
      " |  For a comparison of the different scalers, transformers, and normalizers,\n",
      " |  see :ref:`examples/preprocessing/plot_all_scaling.py\n",
      " |  <sphx_glr_auto_examples_preprocessing_plot_all_scaling.py>`.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      MinMaxScaler\n",
      " |      sklearn.base.TransformerMixin\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, feature_range=(0, 1), *, copy=True, clip=False)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  fit(self, X, y=None)\n",
      " |      Compute the minimum and maximum to be used for later scaling.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          The data used to compute the per-feature minimum and maximum\n",
      " |          used for later scaling along the features axis.\n",
      " |      \n",
      " |      y : None\n",
      " |          Ignored.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Fitted scaler.\n",
      " |  \n",
      " |  inverse_transform(self, X)\n",
      " |      Undo the scaling of X according to feature_range.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Input data that will be transformed. It cannot be sparse.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Xt : ndarray of shape (n_samples, n_features)\n",
      " |          Transformed data.\n",
      " |  \n",
      " |  partial_fit(self, X, y=None)\n",
      " |      Online computation of min and max on X for later scaling.\n",
      " |      \n",
      " |      All of X is processed as a single batch. This is intended for cases\n",
      " |      when :meth:`fit` is not feasible due to very large number of\n",
      " |      `n_samples` or because X is read from a continuous stream.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          The data used to compute the mean and standard deviation\n",
      " |          used for later scaling along the features axis.\n",
      " |      \n",
      " |      y : None\n",
      " |          Ignored.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Fitted scaler.\n",
      " |  \n",
      " |  transform(self, X)\n",
      " |      Scale features of X according to feature_range.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Input data that will be transformed.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Xt : ndarray of shape (n_samples, n_features)\n",
      " |          Transformed data.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.TransformerMixin:\n",
      " |  \n",
      " |  fit_transform(self, X, y=None, **fit_params)\n",
      " |      Fit to data, then transform it.\n",
      " |      \n",
      " |      Fits transformer to `X` and `y` with optional parameters `fit_params`\n",
      " |      and returns a transformed version of `X`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Input samples.\n",
      " |      \n",
      " |      y :  array-like of shape (n_samples,) or (n_samples, n_outputs),                 default=None\n",
      " |          Target values (None for unsupervised transformations).\n",
      " |      \n",
      " |      **fit_params : dict\n",
      " |          Additional fit parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_new : ndarray array of shape (n_samples, n_features_new)\n",
      " |          Transformed array.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.TransformerMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : dict\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      " |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      " |      possible to update each component of a nested object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : estimator instance\n",
      " |          Estimator instance.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(MinMaxScaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "owned-granny",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dependent-digit",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler()"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "trying-italian",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = scaler.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "unexpected-gentleman",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.74046017 0.32583248]\n",
      " [0.43166001 0.2555088 ]\n",
      " [0.18468554 0.70500664]\n",
      " [0.52955895 0.93551377]\n",
      " [0.52907398 0.39249753]]\n",
      "0.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(X_train[:5])\n",
    "print(X_train.min())\n",
    "print(X_train.max())\n",
    "#Data is properly scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "novel-mapping",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "acute-richardson",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Time to create NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "incomplete-concert",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "placed-correction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Sequential in module tensorflow.python.keras.engine.sequential:\n",
      "\n",
      "class Sequential(tensorflow.python.keras.engine.functional.Functional)\n",
      " |  Sequential(*args, **kwargs)\n",
      " |  \n",
      " |  `Sequential` groups a linear stack of layers into a `tf.keras.Model`.\n",
      " |  \n",
      " |  `Sequential` provides training and inference features on this model.\n",
      " |  \n",
      " |  Examples:\n",
      " |  \n",
      " |  >>> # Optionally, the first layer can receive an `input_shape` argument:\n",
      " |  >>> model = tf.keras.Sequential()\n",
      " |  >>> model.add(tf.keras.layers.Dense(8, input_shape=(16,)))\n",
      " |  >>> # Afterwards, we do automatic shape inference:\n",
      " |  >>> model.add(tf.keras.layers.Dense(4))\n",
      " |  \n",
      " |  >>> # This is identical to the following:\n",
      " |  >>> model = tf.keras.Sequential()\n",
      " |  >>> model.add(tf.keras.Input(shape=(16,)))\n",
      " |  >>> model.add(tf.keras.layers.Dense(8))\n",
      " |  \n",
      " |  >>> # Note that you can also omit the `input_shape` argument.\n",
      " |  >>> # In that case the model doesn't have any weights until the first call\n",
      " |  >>> # to a training/evaluation method (since it isn't yet built):\n",
      " |  >>> model = tf.keras.Sequential()\n",
      " |  >>> model.add(tf.keras.layers.Dense(8))\n",
      " |  >>> model.add(tf.keras.layers.Dense(4))\n",
      " |  >>> # model.weights not created yet\n",
      " |  \n",
      " |  >>> # Whereas if you specify the input shape, the model gets built\n",
      " |  >>> # continuously as you are adding layers:\n",
      " |  >>> model = tf.keras.Sequential()\n",
      " |  >>> model.add(tf.keras.layers.Dense(8, input_shape=(16,)))\n",
      " |  >>> model.add(tf.keras.layers.Dense(4))\n",
      " |  >>> len(model.weights)\n",
      " |  4\n",
      " |  \n",
      " |  >>> # When using the delayed-build pattern (no input shape specified), you can\n",
      " |  >>> # choose to manually build your model by calling\n",
      " |  >>> # `build(batch_input_shape)`:\n",
      " |  >>> model = tf.keras.Sequential()\n",
      " |  >>> model.add(tf.keras.layers.Dense(8))\n",
      " |  >>> model.add(tf.keras.layers.Dense(4))\n",
      " |  >>> model.build((None, 16))\n",
      " |  >>> len(model.weights)\n",
      " |  4\n",
      " |  \n",
      " |  ```python\n",
      " |  # Note that when using the delayed-build pattern (no input shape specified),\n",
      " |  # the model gets built the first time you call `fit`, `eval`, or `predict`,\n",
      " |  # or the first time you call the model on some input data.\n",
      " |  model = tf.keras.Sequential()\n",
      " |  model.add(tf.keras.layers.Dense(8))\n",
      " |  model.add(tf.keras.layers.Dense(1))\n",
      " |  model.compile(optimizer='sgd', loss='mse')\n",
      " |  # This builds the model for the first time:\n",
      " |  model.fit(x, y, batch_size=32, epochs=10)\n",
      " |  ```\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Sequential\n",
      " |      tensorflow.python.keras.engine.functional.Functional\n",
      " |      tensorflow.python.keras.engine.training.Model\n",
      " |      tensorflow.python.keras.engine.base_layer.Layer\n",
      " |      tensorflow.python.module.module.Module\n",
      " |      tensorflow.python.training.tracking.tracking.AutoTrackable\n",
      " |      tensorflow.python.training.tracking.base.Trackable\n",
      " |      tensorflow.python.keras.utils.version_utils.LayerVersionSelector\n",
      " |      tensorflow.python.keras.utils.version_utils.ModelVersionSelector\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, layers=None, name=None)\n",
      " |      Creates a `Sequential` model instance.\n",
      " |      \n",
      " |      Args:\n",
      " |        layers: Optional list of layers to add to the model.\n",
      " |        name: Optional name for the model.\n",
      " |  \n",
      " |  add(self, layer)\n",
      " |      Adds a layer instance on top of the layer stack.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          layer: layer instance.\n",
      " |      \n",
      " |      Raises:\n",
      " |          TypeError: If `layer` is not a layer instance.\n",
      " |          ValueError: In case the `layer` argument does not\n",
      " |              know its input shape.\n",
      " |          ValueError: In case the `layer` argument has\n",
      " |              multiple output tensors, or is already connected\n",
      " |              somewhere else (forbidden in `Sequential` models).\n",
      " |  \n",
      " |  build(self, input_shape=None)\n",
      " |      Builds the model based on input shapes received.\n",
      " |      \n",
      " |      This is to be used for subclassed models, which do not know at instantiation\n",
      " |      time what their inputs look like.\n",
      " |      \n",
      " |      This method only exists for users who want to call `model.build()` in a\n",
      " |      standalone way (as a substitute for calling the model on real data to\n",
      " |      build it). It will never be called by the framework (and thus it will\n",
      " |      never throw unexpected errors in an unrelated workflow).\n",
      " |      \n",
      " |      Args:\n",
      " |       input_shape: Single tuple, TensorShape, or list/dict of shapes, where\n",
      " |           shapes are tuples, integers, or TensorShapes.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError:\n",
      " |          1. In case of invalid user-provided data (not of type tuple,\n",
      " |             list, TensorShape, or dict).\n",
      " |          2. If the model requires call arguments that are agnostic\n",
      " |             to the input shapes (positional or kwarg in call signature).\n",
      " |          3. If not all layers were properly built.\n",
      " |          4. If float type inputs are not supported within the layers.\n",
      " |      \n",
      " |        In each of these cases, the user should build their model by calling it\n",
      " |        on real tensor data.\n",
      " |  \n",
      " |  call(self, inputs, training=None, mask=None)\n",
      " |      Calls the model on new inputs.\n",
      " |      \n",
      " |      In this case `call` just reapplies\n",
      " |      all ops in the graph to the new inputs\n",
      " |      (e.g. build a new computational graph from the provided inputs).\n",
      " |      \n",
      " |      Arguments:\n",
      " |          inputs: A tensor or list of tensors.\n",
      " |          training: Boolean or boolean scalar tensor, indicating whether to run\n",
      " |            the `Network` in training mode or inference mode.\n",
      " |          mask: A mask or list of masks. A mask can be\n",
      " |              either a tensor or None (no mask).\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tensor if there is a single output, or\n",
      " |          a list of tensors if there are more than one outputs.\n",
      " |  \n",
      " |  compute_mask(self, inputs, mask)\n",
      " |      Computes an output mask tensor.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          inputs: Tensor or list of tensors.\n",
      " |          mask: Tensor or list of tensors.\n",
      " |      \n",
      " |      Returns:\n",
      " |          None or a tensor (or list of tensors,\n",
      " |              one per output tensor of the layer).\n",
      " |  \n",
      " |  compute_output_shape(self, input_shape)\n",
      " |      Computes the output shape of the layer.\n",
      " |      \n",
      " |      If the layer has not been built, this method will call `build` on the\n",
      " |      layer. This assumes that the layer will later be used with inputs that\n",
      " |      match the input shape provided here.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          input_shape: Shape tuple (tuple of integers)\n",
      " |              or list of shape tuples (one per output tensor of the layer).\n",
      " |              Shape tuples can include None for free dimensions,\n",
      " |              instead of an integer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          An input shape tuple.\n",
      " |  \n",
      " |  get_config(self)\n",
      " |      Returns the config of the layer.\n",
      " |      \n",
      " |      A layer config is a Python dictionary (serializable)\n",
      " |      containing the configuration of a layer.\n",
      " |      The same layer can be reinstantiated later\n",
      " |      (without its trained weights) from this configuration.\n",
      " |      \n",
      " |      The config of a layer does not include connectivity\n",
      " |      information, nor the layer class name. These are handled\n",
      " |      by `Network` (one layer of abstraction above).\n",
      " |      \n",
      " |      Returns:\n",
      " |          Python dictionary.\n",
      " |  \n",
      " |  pop(self)\n",
      " |      Removes the last layer in the model.\n",
      " |      \n",
      " |      Raises:\n",
      " |          TypeError: if there are no layers in the model.\n",
      " |  \n",
      " |  predict_classes(self, x, batch_size=32, verbose=0)\n",
      " |      Generate class predictions for the input samples.\n",
      " |      \n",
      " |      The input samples are processed batch by batch.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          x: input data, as a Numpy array or list of Numpy arrays\n",
      " |              (if the model has multiple inputs).\n",
      " |          batch_size: integer.\n",
      " |          verbose: verbosity mode, 0 or 1.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A numpy array of class predictions.\n",
      " |  \n",
      " |  predict_proba(self, x, batch_size=32, verbose=0)\n",
      " |      Generates class probability predictions for the input samples.\n",
      " |      \n",
      " |      The input samples are processed batch by batch.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          x: input data, as a Numpy array or list of Numpy arrays\n",
      " |              (if the model has multiple inputs).\n",
      " |          batch_size: integer.\n",
      " |          verbose: verbosity mode, 0 or 1.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A Numpy array of probability predictions.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods defined here:\n",
      " |  \n",
      " |  from_config(config, custom_objects=None) from builtins.type\n",
      " |      Instantiates a Model from its config (output of `get_config()`).\n",
      " |      \n",
      " |      Arguments:\n",
      " |          config: Model config dictionary.\n",
      " |          custom_objects: Optional dictionary mapping names\n",
      " |              (strings) to custom classes or functions to be\n",
      " |              considered during deserialization.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A model instance.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: In case of improperly formatted config dict.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  input_spec\n",
      " |      `InputSpec` instance(s) describing the input format for this layer.\n",
      " |      \n",
      " |      When you create a layer subclass, you can set `self.input_spec` to enable\n",
      " |      the layer to run input compatibility checks when it is called.\n",
      " |      Consider a `Conv2D` layer: it can only be called on a single input tensor\n",
      " |      of rank 4. As such, you can set, in `__init__()`:\n",
      " |      \n",
      " |      ```python\n",
      " |      self.input_spec = tf.keras.layers.InputSpec(ndim=4)\n",
      " |      ```\n",
      " |      \n",
      " |      Now, if you try to call the layer on an input that isn't rank 4\n",
      " |      (for instance, an input of shape `(2,)`, it will raise a nicely-formatted\n",
      " |      error:\n",
      " |      \n",
      " |      ```\n",
      " |      ValueError: Input 0 of layer conv2d is incompatible with the layer:\n",
      " |      expected ndim=4, found ndim=1. Full shape received: [2]\n",
      " |      ```\n",
      " |      \n",
      " |      Input checks that can be specified via `input_spec` include:\n",
      " |      - Structure (e.g. a single input, a list of 2 inputs, etc)\n",
      " |      - Shape\n",
      " |      - Rank (ndim)\n",
      " |      - Dtype\n",
      " |      \n",
      " |      For more information, see `tf.keras.layers.InputSpec`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A `tf.keras.layers.InputSpec` instance, or nested structure thereof.\n",
      " |  \n",
      " |  layers\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.keras.engine.functional.Functional:\n",
      " |  \n",
      " |  input\n",
      " |      Retrieves the input tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one input,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input tensor or list of input tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |        AttributeError: If no inbound nodes are found.\n",
      " |  \n",
      " |  input_shape\n",
      " |      Retrieves the input shape(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one input,\n",
      " |      i.e. if it is connected to one incoming layer, or if all inputs\n",
      " |      have the same shape.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input shape, as an integer shape tuple\n",
      " |          (or list of shape tuples, one tuple per input tensor).\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer has no defined input_shape.\n",
      " |          RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  output\n",
      " |      Retrieves the output tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one output,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Output tensor or list of output tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |        AttributeError: if the layer is connected to more than one incoming\n",
      " |          layers.\n",
      " |        RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  output_shape\n",
      " |      Retrieves the output shape(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has one output,\n",
      " |      or if all outputs have the same shape.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Output shape, as an integer shape tuple\n",
      " |          (or list of shape tuples, one tuple per output tensor).\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer has no defined output shape.\n",
      " |          RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from tensorflow.python.keras.engine.training.Model:\n",
      " |  \n",
      " |  __setattr__(self, name, value)\n",
      " |      Support self.foo = trackable syntax.\n",
      " |  \n",
      " |  compile(self, optimizer='rmsprop', loss=None, metrics=None, loss_weights=None, weighted_metrics=None, run_eagerly=None, steps_per_execution=None, **kwargs)\n",
      " |      Configures the model for training.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          optimizer: String (name of optimizer) or optimizer instance. See\n",
      " |            `tf.keras.optimizers`.\n",
      " |          loss: String (name of objective function), objective function or\n",
      " |            `tf.keras.losses.Loss` instance. See `tf.keras.losses`. An objective\n",
      " |            function is any callable with the signature `loss = fn(y_true,\n",
      " |            y_pred)`, where y_true = ground truth values with shape =\n",
      " |            `[batch_size, d0, .. dN]`, except sparse loss functions such as sparse\n",
      " |            categorical crossentropy where shape = `[batch_size, d0, .. dN-1]`.\n",
      " |            y_pred = predicted values with shape = `[batch_size, d0, .. dN]`. It\n",
      " |            returns a weighted loss float tensor. If a custom `Loss` instance is\n",
      " |            used and reduction is set to NONE, return value has the shape\n",
      " |            [batch_size, d0, .. dN-1] ie. per-sample or per-timestep loss values;\n",
      " |            otherwise, it is a scalar. If the model has multiple outputs, you can\n",
      " |            use a different loss on each output by passing a dictionary or a list\n",
      " |            of losses. The loss value that will be minimized by the model will\n",
      " |            then be the sum of all individual losses.\n",
      " |          metrics: List of metrics to be evaluated by the model during training\n",
      " |            and testing. Each of this can be a string (name of a built-in\n",
      " |            function), function or a `tf.keras.metrics.Metric` instance. See\n",
      " |            `tf.keras.metrics`. Typically you will use `metrics=['accuracy']`. A\n",
      " |            function is any callable with the signature `result = fn(y_true,\n",
      " |            y_pred)`. To specify different metrics for different outputs of a\n",
      " |            multi-output model, you could also pass a dictionary, such as\n",
      " |              `metrics={'output_a': 'accuracy', 'output_b': ['accuracy', 'mse']}`.\n",
      " |                You can also pass a list (len = len(outputs)) of lists of metrics\n",
      " |                such as `metrics=[['accuracy'], ['accuracy', 'mse']]` or\n",
      " |                `metrics=['accuracy', ['accuracy', 'mse']]`. When you pass the\n",
      " |                strings 'accuracy' or 'acc', we convert this to one of\n",
      " |                `tf.keras.metrics.BinaryAccuracy`,\n",
      " |                `tf.keras.metrics.CategoricalAccuracy`,\n",
      " |                `tf.keras.metrics.SparseCategoricalAccuracy` based on the loss\n",
      " |                function used and the model output shape. We do a similar\n",
      " |                conversion for the strings 'crossentropy' and 'ce' as well.\n",
      " |          loss_weights: Optional list or dictionary specifying scalar coefficients\n",
      " |            (Python floats) to weight the loss contributions of different model\n",
      " |            outputs. The loss value that will be minimized by the model will then\n",
      " |            be the *weighted sum* of all individual losses, weighted by the\n",
      " |            `loss_weights` coefficients.\n",
      " |              If a list, it is expected to have a 1:1 mapping to the model's\n",
      " |                outputs. If a dict, it is expected to map output names (strings)\n",
      " |                to scalar coefficients.\n",
      " |          weighted_metrics: List of metrics to be evaluated and weighted by\n",
      " |            sample_weight or class_weight during training and testing.\n",
      " |          run_eagerly: Bool. Defaults to `False`. If `True`, this `Model`'s\n",
      " |            logic will not be wrapped in a `tf.function`. Recommended to leave\n",
      " |            this as `None` unless your `Model` cannot be run inside a\n",
      " |            `tf.function`.\n",
      " |          steps_per_execution: Int. Defaults to 1. The number of batches to\n",
      " |            run during each `tf.function` call. Running multiple batches\n",
      " |            inside a single `tf.function` call can greatly improve performance\n",
      " |            on TPUs or small models with a large Python overhead.\n",
      " |            At most, one full epoch will be run each\n",
      " |            execution. If a number larger than the size of the epoch is passed,\n",
      " |            the execution will be truncated to the size of the epoch.\n",
      " |            Note that if `steps_per_execution` is set to `N`,\n",
      " |            `Callback.on_batch_begin` and `Callback.on_batch_end` methods\n",
      " |            will only be called every `N` batches\n",
      " |            (i.e. before/after each `tf.function` execution).\n",
      " |          **kwargs: Arguments supported for backwards compatibility only.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: In case of invalid arguments for\n",
      " |              `optimizer`, `loss` or `metrics`.\n",
      " |  \n",
      " |  evaluate(self, x=None, y=None, batch_size=None, verbose=1, sample_weight=None, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False, return_dict=False)\n",
      " |      Returns the loss value & metrics values for the model in test mode.\n",
      " |      \n",
      " |      Computation is done in batches (see the `batch_size` arg.)\n",
      " |      \n",
      " |      Arguments:\n",
      " |          x: Input data. It could be:\n",
      " |            - A Numpy array (or array-like), or a list of arrays\n",
      " |              (in case the model has multiple inputs).\n",
      " |            - A TensorFlow tensor, or a list of tensors\n",
      " |              (in case the model has multiple inputs).\n",
      " |            - A dict mapping input names to the corresponding array/tensors,\n",
      " |              if the model has named inputs.\n",
      " |            - A `tf.data` dataset. Should return a tuple\n",
      " |              of either `(inputs, targets)` or\n",
      " |              `(inputs, targets, sample_weights)`.\n",
      " |            - A generator or `keras.utils.Sequence` returning `(inputs, targets)`\n",
      " |              or `(inputs, targets, sample_weights)`.\n",
      " |            A more detailed description of unpacking behavior for iterator types\n",
      " |            (Dataset, generator, Sequence) is given in the `Unpacking behavior\n",
      " |            for iterator-like inputs` section of `Model.fit`.\n",
      " |          y: Target data. Like the input data `x`, it could be either Numpy\n",
      " |            array(s) or TensorFlow tensor(s). It should be consistent with `x`\n",
      " |            (you cannot have Numpy inputs and tensor targets, or inversely). If\n",
      " |            `x` is a dataset, generator or `keras.utils.Sequence` instance, `y`\n",
      " |            should not be specified (since targets will be obtained from the\n",
      " |            iterator/dataset).\n",
      " |          batch_size: Integer or `None`. Number of samples per batch of\n",
      " |            computation. If unspecified, `batch_size` will default to 32. Do not\n",
      " |            specify the `batch_size` if your data is in the form of a dataset,\n",
      " |            generators, or `keras.utils.Sequence` instances (since they generate\n",
      " |            batches).\n",
      " |          verbose: 0 or 1. Verbosity mode. 0 = silent, 1 = progress bar.\n",
      " |          sample_weight: Optional Numpy array of weights for the test samples,\n",
      " |            used for weighting the loss function. You can either pass a flat (1D)\n",
      " |            Numpy array with the same length as the input samples\n",
      " |              (1:1 mapping between weights and samples), or in the case of\n",
      " |                temporal data, you can pass a 2D array with shape `(samples,\n",
      " |                sequence_length)`, to apply a different weight to every timestep\n",
      " |                of every sample. This argument is not supported when `x` is a\n",
      " |                dataset, instead pass sample weights as the third element of `x`.\n",
      " |          steps: Integer or `None`. Total number of steps (batches of samples)\n",
      " |            before declaring the evaluation round finished. Ignored with the\n",
      " |            default value of `None`. If x is a `tf.data` dataset and `steps` is\n",
      " |            None, 'evaluate' will run until the dataset is exhausted. This\n",
      " |            argument is not supported with array inputs.\n",
      " |          callbacks: List of `keras.callbacks.Callback` instances. List of\n",
      " |            callbacks to apply during evaluation. See\n",
      " |            [callbacks](/api_docs/python/tf/keras/callbacks).\n",
      " |          max_queue_size: Integer. Used for generator or `keras.utils.Sequence`\n",
      " |            input only. Maximum size for the generator queue. If unspecified,\n",
      " |            `max_queue_size` will default to 10.\n",
      " |          workers: Integer. Used for generator or `keras.utils.Sequence` input\n",
      " |            only. Maximum number of processes to spin up when using process-based\n",
      " |            threading. If unspecified, `workers` will default to 1. If 0, will\n",
      " |            execute the generator on the main thread.\n",
      " |          use_multiprocessing: Boolean. Used for generator or\n",
      " |            `keras.utils.Sequence` input only. If `True`, use process-based\n",
      " |            threading. If unspecified, `use_multiprocessing` will default to\n",
      " |            `False`. Note that because this implementation relies on\n",
      " |            multiprocessing, you should not pass non-picklable arguments to the\n",
      " |            generator as they can't be passed easily to children processes.\n",
      " |          return_dict: If `True`, loss and metric results are returned as a dict,\n",
      " |            with each key being the name of the metric. If `False`, they are\n",
      " |            returned as a list.\n",
      " |      \n",
      " |      See the discussion of `Unpacking behavior for iterator-like inputs` for\n",
      " |      `Model.fit`.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Scalar test loss (if the model has a single output and no metrics)\n",
      " |          or list of scalars (if the model has multiple outputs\n",
      " |          and/or metrics). The attribute `model.metrics_names` will give you\n",
      " |          the display labels for the scalar outputs.\n",
      " |      \n",
      " |      Raises:\n",
      " |          RuntimeError: If `model.evaluate` is wrapped in `tf.function`.\n",
      " |          ValueError: in case of invalid arguments.\n",
      " |  \n",
      " |  evaluate_generator(self, generator, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False, verbose=0)\n",
      " |      Evaluates the model on a data generator.\n",
      " |      \n",
      " |      DEPRECATED:\n",
      " |        `Model.evaluate` now supports generators, so there is no longer any need\n",
      " |        to use this endpoint.\n",
      " |  \n",
      " |  fit(self, x=None, y=None, batch_size=None, epochs=1, verbose=1, callbacks=None, validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0, steps_per_epoch=None, validation_steps=None, validation_batch_size=None, validation_freq=1, max_queue_size=10, workers=1, use_multiprocessing=False)\n",
      " |      Trains the model for a fixed number of epochs (iterations on a dataset).\n",
      " |      \n",
      " |      Arguments:\n",
      " |          x: Input data. It could be:\n",
      " |            - A Numpy array (or array-like), or a list of arrays\n",
      " |              (in case the model has multiple inputs).\n",
      " |            - A TensorFlow tensor, or a list of tensors\n",
      " |              (in case the model has multiple inputs).\n",
      " |            - A dict mapping input names to the corresponding array/tensors,\n",
      " |              if the model has named inputs.\n",
      " |            - A `tf.data` dataset. Should return a tuple\n",
      " |              of either `(inputs, targets)` or\n",
      " |              `(inputs, targets, sample_weights)`.\n",
      " |            - A generator or `keras.utils.Sequence` returning `(inputs, targets)`\n",
      " |              or `(inputs, targets, sample_weights)`.\n",
      " |            A more detailed description of unpacking behavior for iterator types\n",
      " |            (Dataset, generator, Sequence) is given below.\n",
      " |          y: Target data. Like the input data `x`,\n",
      " |            it could be either Numpy array(s) or TensorFlow tensor(s).\n",
      " |            It should be consistent with `x` (you cannot have Numpy inputs and\n",
      " |            tensor targets, or inversely). If `x` is a dataset, generator,\n",
      " |            or `keras.utils.Sequence` instance, `y` should\n",
      " |            not be specified (since targets will be obtained from `x`).\n",
      " |          batch_size: Integer or `None`.\n",
      " |              Number of samples per gradient update.\n",
      " |              If unspecified, `batch_size` will default to 32.\n",
      " |              Do not specify the `batch_size` if your data is in the\n",
      " |              form of datasets, generators, or `keras.utils.Sequence` instances\n",
      " |              (since they generate batches).\n",
      " |          epochs: Integer. Number of epochs to train the model.\n",
      " |              An epoch is an iteration over the entire `x` and `y`\n",
      " |              data provided.\n",
      " |              Note that in conjunction with `initial_epoch`,\n",
      " |              `epochs` is to be understood as \"final epoch\".\n",
      " |              The model is not trained for a number of iterations\n",
      " |              given by `epochs`, but merely until the epoch\n",
      " |              of index `epochs` is reached.\n",
      " |          verbose: 0, 1, or 2. Verbosity mode.\n",
      " |              0 = silent, 1 = progress bar, 2 = one line per epoch.\n",
      " |              Note that the progress bar is not particularly useful when\n",
      " |              logged to a file, so verbose=2 is recommended when not running\n",
      " |              interactively (eg, in a production environment).\n",
      " |          callbacks: List of `keras.callbacks.Callback` instances.\n",
      " |              List of callbacks to apply during training.\n",
      " |              See `tf.keras.callbacks`. Note `tf.keras.callbacks.ProgbarLogger`\n",
      " |              and `tf.keras.callbacks.History` callbacks are created automatically\n",
      " |              and need not be passed into `model.fit`.\n",
      " |              `tf.keras.callbacks.ProgbarLogger` is created or not based on\n",
      " |              `verbose` argument to `model.fit`.\n",
      " |          validation_split: Float between 0 and 1.\n",
      " |              Fraction of the training data to be used as validation data.\n",
      " |              The model will set apart this fraction of the training data,\n",
      " |              will not train on it, and will evaluate\n",
      " |              the loss and any model metrics\n",
      " |              on this data at the end of each epoch.\n",
      " |              The validation data is selected from the last samples\n",
      " |              in the `x` and `y` data provided, before shuffling. This argument is\n",
      " |              not supported when `x` is a dataset, generator or\n",
      " |             `keras.utils.Sequence` instance.\n",
      " |          validation_data: Data on which to evaluate\n",
      " |              the loss and any model metrics at the end of each epoch.\n",
      " |              The model will not be trained on this data. Thus, note the fact\n",
      " |              that the validation loss of data provided using `validation_split`\n",
      " |              or `validation_data` is not affected by regularization layers like\n",
      " |              noise and dropout.\n",
      " |              `validation_data` will override `validation_split`.\n",
      " |              `validation_data` could be:\n",
      " |                - tuple `(x_val, y_val)` of Numpy arrays or tensors\n",
      " |                - tuple `(x_val, y_val, val_sample_weights)` of Numpy arrays\n",
      " |                - dataset\n",
      " |              For the first two cases, `batch_size` must be provided.\n",
      " |              For the last case, `validation_steps` could be provided.\n",
      " |              Note that `validation_data` does not support all the data types that\n",
      " |              are supported in `x`, eg, dict, generator or `keras.utils.Sequence`.\n",
      " |          shuffle: Boolean (whether to shuffle the training data\n",
      " |              before each epoch) or str (for 'batch'). This argument is ignored\n",
      " |              when `x` is a generator. 'batch' is a special option for dealing\n",
      " |              with the limitations of HDF5 data; it shuffles in batch-sized\n",
      " |              chunks. Has no effect when `steps_per_epoch` is not `None`.\n",
      " |          class_weight: Optional dictionary mapping class indices (integers)\n",
      " |              to a weight (float) value, used for weighting the loss function\n",
      " |              (during training only).\n",
      " |              This can be useful to tell the model to\n",
      " |              \"pay more attention\" to samples from\n",
      " |              an under-represented class.\n",
      " |          sample_weight: Optional Numpy array of weights for\n",
      " |              the training samples, used for weighting the loss function\n",
      " |              (during training only). You can either pass a flat (1D)\n",
      " |              Numpy array with the same length as the input samples\n",
      " |              (1:1 mapping between weights and samples),\n",
      " |              or in the case of temporal data,\n",
      " |              you can pass a 2D array with shape\n",
      " |              `(samples, sequence_length)`,\n",
      " |              to apply a different weight to every timestep of every sample. This\n",
      " |              argument is not supported when `x` is a dataset, generator, or\n",
      " |             `keras.utils.Sequence` instance, instead provide the sample_weights\n",
      " |              as the third element of `x`.\n",
      " |          initial_epoch: Integer.\n",
      " |              Epoch at which to start training\n",
      " |              (useful for resuming a previous training run).\n",
      " |          steps_per_epoch: Integer or `None`.\n",
      " |              Total number of steps (batches of samples)\n",
      " |              before declaring one epoch finished and starting the\n",
      " |              next epoch. When training with input tensors such as\n",
      " |              TensorFlow data tensors, the default `None` is equal to\n",
      " |              the number of samples in your dataset divided by\n",
      " |              the batch size, or 1 if that cannot be determined. If x is a\n",
      " |              `tf.data` dataset, and 'steps_per_epoch'\n",
      " |              is None, the epoch will run until the input dataset is exhausted.\n",
      " |              When passing an infinitely repeating dataset, you must specify the\n",
      " |              `steps_per_epoch` argument. This argument is not supported with\n",
      " |              array inputs.\n",
      " |          validation_steps: Only relevant if `validation_data` is provided and\n",
      " |              is a `tf.data` dataset. Total number of steps (batches of\n",
      " |              samples) to draw before stopping when performing validation\n",
      " |              at the end of every epoch. If 'validation_steps' is None, validation\n",
      " |              will run until the `validation_data` dataset is exhausted. In the\n",
      " |              case of an infinitely repeated dataset, it will run into an\n",
      " |              infinite loop. If 'validation_steps' is specified and only part of\n",
      " |              the dataset will be consumed, the evaluation will start from the\n",
      " |              beginning of the dataset at each epoch. This ensures that the same\n",
      " |              validation samples are used every time.\n",
      " |          validation_batch_size: Integer or `None`.\n",
      " |              Number of samples per validation batch.\n",
      " |              If unspecified, will default to `batch_size`.\n",
      " |              Do not specify the `validation_batch_size` if your data is in the\n",
      " |              form of datasets, generators, or `keras.utils.Sequence` instances\n",
      " |              (since they generate batches).\n",
      " |          validation_freq: Only relevant if validation data is provided. Integer\n",
      " |              or `collections_abc.Container` instance (e.g. list, tuple, etc.).\n",
      " |              If an integer, specifies how many training epochs to run before a\n",
      " |              new validation run is performed, e.g. `validation_freq=2` runs\n",
      " |              validation every 2 epochs. If a Container, specifies the epochs on\n",
      " |              which to run validation, e.g. `validation_freq=[1, 2, 10]` runs\n",
      " |              validation at the end of the 1st, 2nd, and 10th epochs.\n",
      " |          max_queue_size: Integer. Used for generator or `keras.utils.Sequence`\n",
      " |              input only. Maximum size for the generator queue.\n",
      " |              If unspecified, `max_queue_size` will default to 10.\n",
      " |          workers: Integer. Used for generator or `keras.utils.Sequence` input\n",
      " |              only. Maximum number of processes to spin up\n",
      " |              when using process-based threading. If unspecified, `workers`\n",
      " |              will default to 1. If 0, will execute the generator on the main\n",
      " |              thread.\n",
      " |          use_multiprocessing: Boolean. Used for generator or\n",
      " |              `keras.utils.Sequence` input only. If `True`, use process-based\n",
      " |              threading. If unspecified, `use_multiprocessing` will default to\n",
      " |              `False`. Note that because this implementation relies on\n",
      " |              multiprocessing, you should not pass non-picklable arguments to\n",
      " |              the generator as they can't be passed easily to children processes.\n",
      " |      \n",
      " |      Unpacking behavior for iterator-like inputs:\n",
      " |          A common pattern is to pass a tf.data.Dataset, generator, or\n",
      " |        tf.keras.utils.Sequence to the `x` argument of fit, which will in fact\n",
      " |        yield not only features (x) but optionally targets (y) and sample weights.\n",
      " |        Keras requires that the output of such iterator-likes be unambiguous. The\n",
      " |        iterator should return a tuple of length 1, 2, or 3, where the optional\n",
      " |        second and third elements will be used for y and sample_weight\n",
      " |        respectively. Any other type provided will be wrapped in a length one\n",
      " |        tuple, effectively treating everything as 'x'. When yielding dicts, they\n",
      " |        should still adhere to the top-level tuple structure.\n",
      " |        e.g. `({\"x0\": x0, \"x1\": x1}, y)`. Keras will not attempt to separate\n",
      " |        features, targets, and weights from the keys of a single dict.\n",
      " |          A notable unsupported data type is the namedtuple. The reason is that\n",
      " |        it behaves like both an ordered datatype (tuple) and a mapping\n",
      " |        datatype (dict). So given a namedtuple of the form:\n",
      " |            `namedtuple(\"example_tuple\", [\"y\", \"x\"])`\n",
      " |        it is ambiguous whether to reverse the order of the elements when\n",
      " |        interpreting the value. Even worse is a tuple of the form:\n",
      " |            `namedtuple(\"other_tuple\", [\"x\", \"y\", \"z\"])`\n",
      " |        where it is unclear if the tuple was intended to be unpacked into x, y,\n",
      " |        and sample_weight or passed through as a single element to `x`. As a\n",
      " |        result the data processing code will simply raise a ValueError if it\n",
      " |        encounters a namedtuple. (Along with instructions to remedy the issue.)\n",
      " |      \n",
      " |      Returns:\n",
      " |          A `History` object. Its `History.history` attribute is\n",
      " |          a record of training loss values and metrics values\n",
      " |          at successive epochs, as well as validation loss values\n",
      " |          and validation metrics values (if applicable).\n",
      " |      \n",
      " |      Raises:\n",
      " |          RuntimeError: 1. If the model was never compiled or,\n",
      " |          2. If `model.fit` is  wrapped in `tf.function`.\n",
      " |      \n",
      " |          ValueError: In case of mismatch between the provided input data\n",
      " |              and what the model expects or when the input data is empty.\n",
      " |  \n",
      " |  fit_generator(self, generator, steps_per_epoch=None, epochs=1, verbose=1, callbacks=None, validation_data=None, validation_steps=None, validation_freq=1, class_weight=None, max_queue_size=10, workers=1, use_multiprocessing=False, shuffle=True, initial_epoch=0)\n",
      " |      Fits the model on data yielded batch-by-batch by a Python generator.\n",
      " |      \n",
      " |      DEPRECATED:\n",
      " |        `Model.fit` now supports generators, so there is no longer any need to use\n",
      " |        this endpoint.\n",
      " |  \n",
      " |  get_layer(self, name=None, index=None)\n",
      " |      Retrieves a layer based on either its name (unique) or index.\n",
      " |      \n",
      " |      If `name` and `index` are both provided, `index` will take precedence.\n",
      " |      Indices are based on order of horizontal graph traversal (bottom-up).\n",
      " |      \n",
      " |      Arguments:\n",
      " |          name: String, name of layer.\n",
      " |          index: Integer, index of layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A layer instance.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: In case of invalid layer name or index.\n",
      " |  \n",
      " |  get_weights(self)\n",
      " |      Retrieves the weights of the model.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A flat list of Numpy arrays.\n",
      " |  \n",
      " |  load_weights(self, filepath, by_name=False, skip_mismatch=False, options=None)\n",
      " |      Loads all layer weights, either from a TensorFlow or an HDF5 weight file.\n",
      " |      \n",
      " |      If `by_name` is False weights are loaded based on the network's\n",
      " |      topology. This means the architecture should be the same as when the weights\n",
      " |      were saved.  Note that layers that don't have weights are not taken into\n",
      " |      account in the topological ordering, so adding or removing layers is fine as\n",
      " |      long as they don't have weights.\n",
      " |      \n",
      " |      If `by_name` is True, weights are loaded into layers only if they share the\n",
      " |      same name. This is useful for fine-tuning or transfer-learning models where\n",
      " |      some of the layers have changed.\n",
      " |      \n",
      " |      Only topological loading (`by_name=False`) is supported when loading weights\n",
      " |      from the TensorFlow format. Note that topological loading differs slightly\n",
      " |      between TensorFlow and HDF5 formats for user-defined classes inheriting from\n",
      " |      `tf.keras.Model`: HDF5 loads based on a flattened list of weights, while the\n",
      " |      TensorFlow format loads based on the object-local names of attributes to\n",
      " |      which layers are assigned in the `Model`'s constructor.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          filepath: String, path to the weights file to load. For weight files in\n",
      " |              TensorFlow format, this is the file prefix (the same as was passed\n",
      " |              to `save_weights`).\n",
      " |          by_name: Boolean, whether to load weights by name or by topological\n",
      " |              order. Only topological loading is supported for weight files in\n",
      " |              TensorFlow format.\n",
      " |          skip_mismatch: Boolean, whether to skip loading of layers where there is\n",
      " |              a mismatch in the number of weights, or a mismatch in the shape of\n",
      " |              the weight (only valid when `by_name=True`).\n",
      " |          options: Optional `tf.train.CheckpointOptions` object that specifies\n",
      " |              options for loading weights.\n",
      " |      \n",
      " |      Returns:\n",
      " |          When loading a weight file in TensorFlow format, returns the same status\n",
      " |          object as `tf.train.Checkpoint.restore`. When graph building, restore\n",
      " |          ops are run automatically as soon as the network is built (on first call\n",
      " |          for user-defined classes inheriting from `Model`, immediately if it is\n",
      " |          already built).\n",
      " |      \n",
      " |          When loading weights in HDF5 format, returns `None`.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ImportError: If h5py is not available and the weight file is in HDF5\n",
      " |              format.\n",
      " |          ValueError: If `skip_mismatch` is set to `True` when `by_name` is\n",
      " |            `False`.\n",
      " |  \n",
      " |  make_predict_function(self)\n",
      " |      Creates a function that executes one step of inference.\n",
      " |      \n",
      " |      This method can be overridden to support custom inference logic.\n",
      " |      This method is called by `Model.predict` and `Model.predict_on_batch`.\n",
      " |      \n",
      " |      Typically, this method directly controls `tf.function` and\n",
      " |      `tf.distribute.Strategy` settings, and delegates the actual evaluation\n",
      " |      logic to `Model.predict_step`.\n",
      " |      \n",
      " |      This function is cached the first time `Model.predict` or\n",
      " |      `Model.predict_on_batch` is called. The cache is cleared whenever\n",
      " |      `Model.compile` is called.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Function. The function created by this method should accept a\n",
      " |        `tf.data.Iterator`, and return the outputs of the `Model`.\n",
      " |  \n",
      " |  make_test_function(self)\n",
      " |      Creates a function that executes one step of evaluation.\n",
      " |      \n",
      " |      This method can be overridden to support custom evaluation logic.\n",
      " |      This method is called by `Model.evaluate` and `Model.test_on_batch`.\n",
      " |      \n",
      " |      Typically, this method directly controls `tf.function` and\n",
      " |      `tf.distribute.Strategy` settings, and delegates the actual evaluation\n",
      " |      logic to `Model.test_step`.\n",
      " |      \n",
      " |      This function is cached the first time `Model.evaluate` or\n",
      " |      `Model.test_on_batch` is called. The cache is cleared whenever\n",
      " |      `Model.compile` is called.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Function. The function created by this method should accept a\n",
      " |        `tf.data.Iterator`, and return a `dict` containing values that will\n",
      " |        be passed to `tf.keras.Callbacks.on_test_batch_end`.\n",
      " |  \n",
      " |  make_train_function(self)\n",
      " |      Creates a function that executes one step of training.\n",
      " |      \n",
      " |      This method can be overridden to support custom training logic.\n",
      " |      This method is called by `Model.fit` and `Model.train_on_batch`.\n",
      " |      \n",
      " |      Typically, this method directly controls `tf.function` and\n",
      " |      `tf.distribute.Strategy` settings, and delegates the actual training\n",
      " |      logic to `Model.train_step`.\n",
      " |      \n",
      " |      This function is cached the first time `Model.fit` or\n",
      " |      `Model.train_on_batch` is called. The cache is cleared whenever\n",
      " |      `Model.compile` is called.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Function. The function created by this method should accept a\n",
      " |        `tf.data.Iterator`, and return a `dict` containing values that will\n",
      " |        be passed to `tf.keras.Callbacks.on_train_batch_end`, such as\n",
      " |        `{'loss': 0.2, 'accuracy': 0.7}`.\n",
      " |  \n",
      " |  predict(self, x, batch_size=None, verbose=0, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False)\n",
      " |      Generates output predictions for the input samples.\n",
      " |      \n",
      " |      Computation is done in batches. This method is designed for performance in\n",
      " |      large scale inputs. For small amount of inputs that fit in one batch,\n",
      " |      directly using `__call__` is recommended for faster execution, e.g.,\n",
      " |      `model(x)`, or `model(x, training=False)` if you have layers such as\n",
      " |      `tf.keras.layers.BatchNormalization` that behaves differently during\n",
      " |      inference. Also, note the fact that test loss is not affected by\n",
      " |      regularization layers like noise and dropout.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          x: Input samples. It could be:\n",
      " |            - A Numpy array (or array-like), or a list of arrays\n",
      " |              (in case the model has multiple inputs).\n",
      " |            - A TensorFlow tensor, or a list of tensors\n",
      " |              (in case the model has multiple inputs).\n",
      " |            - A `tf.data` dataset.\n",
      " |            - A generator or `keras.utils.Sequence` instance.\n",
      " |            A more detailed description of unpacking behavior for iterator types\n",
      " |            (Dataset, generator, Sequence) is given in the `Unpacking behavior\n",
      " |            for iterator-like inputs` section of `Model.fit`.\n",
      " |          batch_size: Integer or `None`.\n",
      " |              Number of samples per batch.\n",
      " |              If unspecified, `batch_size` will default to 32.\n",
      " |              Do not specify the `batch_size` if your data is in the\n",
      " |              form of dataset, generators, or `keras.utils.Sequence` instances\n",
      " |              (since they generate batches).\n",
      " |          verbose: Verbosity mode, 0 or 1.\n",
      " |          steps: Total number of steps (batches of samples)\n",
      " |              before declaring the prediction round finished.\n",
      " |              Ignored with the default value of `None`. If x is a `tf.data`\n",
      " |              dataset and `steps` is None, `predict` will\n",
      " |              run until the input dataset is exhausted.\n",
      " |          callbacks: List of `keras.callbacks.Callback` instances.\n",
      " |              List of callbacks to apply during prediction.\n",
      " |              See [callbacks](/api_docs/python/tf/keras/callbacks).\n",
      " |          max_queue_size: Integer. Used for generator or `keras.utils.Sequence`\n",
      " |              input only. Maximum size for the generator queue.\n",
      " |              If unspecified, `max_queue_size` will default to 10.\n",
      " |          workers: Integer. Used for generator or `keras.utils.Sequence` input\n",
      " |              only. Maximum number of processes to spin up when using\n",
      " |              process-based threading. If unspecified, `workers` will default\n",
      " |              to 1. If 0, will execute the generator on the main thread.\n",
      " |          use_multiprocessing: Boolean. Used for generator or\n",
      " |              `keras.utils.Sequence` input only. If `True`, use process-based\n",
      " |              threading. If unspecified, `use_multiprocessing` will default to\n",
      " |              `False`. Note that because this implementation relies on\n",
      " |              multiprocessing, you should not pass non-picklable arguments to\n",
      " |              the generator as they can't be passed easily to children processes.\n",
      " |      \n",
      " |      See the discussion of `Unpacking behavior for iterator-like inputs` for\n",
      " |      `Model.fit`. Note that Model.predict uses the same interpretation rules as\n",
      " |      `Model.fit` and `Model.evaluate`, so inputs must be unambiguous for all\n",
      " |      three methods.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Numpy array(s) of predictions.\n",
      " |      \n",
      " |      Raises:\n",
      " |          RuntimeError: If `model.predict` is wrapped in `tf.function`.\n",
      " |          ValueError: In case of mismatch between the provided\n",
      " |              input data and the model's expectations,\n",
      " |              or in case a stateful model receives a number of samples\n",
      " |              that is not a multiple of the batch size.\n",
      " |  \n",
      " |  predict_generator(self, generator, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False, verbose=0)\n",
      " |      Generates predictions for the input samples from a data generator.\n",
      " |      \n",
      " |      DEPRECATED:\n",
      " |        `Model.predict` now supports generators, so there is no longer any need\n",
      " |        to use this endpoint.\n",
      " |  \n",
      " |  predict_on_batch(self, x)\n",
      " |      Returns predictions for a single batch of samples.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          x: Input data. It could be: - A Numpy array (or array-like), or a list\n",
      " |            of arrays (in case the model has multiple inputs). - A TensorFlow\n",
      " |            tensor, or a list of tensors (in case the model has multiple inputs).\n",
      " |      \n",
      " |      Returns:\n",
      " |          Numpy array(s) of predictions.\n",
      " |      \n",
      " |      Raises:\n",
      " |          RuntimeError: If `model.predict_on_batch` is wrapped in `tf.function`.\n",
      " |          ValueError: In case of mismatch between given number of inputs and\n",
      " |            expectations of the model.\n",
      " |  \n",
      " |  predict_step(self, data)\n",
      " |      The logic for one inference step.\n",
      " |      \n",
      " |      This method can be overridden to support custom inference logic.\n",
      " |      This method is called by `Model.make_predict_function`.\n",
      " |      \n",
      " |      This method should contain the mathematical logic for one step of inference.\n",
      " |      This typically includes the forward pass.\n",
      " |      \n",
      " |      Configuration details for *how* this logic is run (e.g. `tf.function` and\n",
      " |      `tf.distribute.Strategy` settings), should be left to\n",
      " |      `Model.make_predict_function`, which can also be overridden.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        data: A nested structure of `Tensor`s.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The result of one inference step, typically the output of calling the\n",
      " |        `Model` on data.\n",
      " |  \n",
      " |  reset_metrics(self)\n",
      " |      Resets the state of all the metrics in the model.\n",
      " |      \n",
      " |      Examples:\n",
      " |      \n",
      " |      >>> inputs = tf.keras.layers.Input(shape=(3,))\n",
      " |      >>> outputs = tf.keras.layers.Dense(2)(inputs)\n",
      " |      >>> model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
      " |      >>> model.compile(optimizer=\"Adam\", loss=\"mse\", metrics=[\"mae\"])\n",
      " |      \n",
      " |      >>> x = np.random.random((2, 3))\n",
      " |      >>> y = np.random.randint(0, 2, (2, 2))\n",
      " |      >>> _ = model.fit(x, y, verbose=0)\n",
      " |      >>> assert all(float(m.result()) for m in model.metrics)\n",
      " |      \n",
      " |      >>> model.reset_metrics()\n",
      " |      >>> assert all(float(m.result()) == 0 for m in model.metrics)\n",
      " |  \n",
      " |  reset_states(self)\n",
      " |  \n",
      " |  save(self, filepath, overwrite=True, include_optimizer=True, save_format=None, signatures=None, options=None, save_traces=True)\n",
      " |      Saves the model to Tensorflow SavedModel or a single HDF5 file.\n",
      " |      \n",
      " |      Please see `tf.keras.models.save_model` or the\n",
      " |      [Serialization and Saving guide](https://keras.io/guides/serialization_and_saving/)\n",
      " |      for details.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          filepath: String, PathLike, path to SavedModel or H5 file to save the\n",
      " |              model.\n",
      " |          overwrite: Whether to silently overwrite any existing file at the\n",
      " |              target location, or provide the user with a manual prompt.\n",
      " |          include_optimizer: If True, save optimizer's state together.\n",
      " |          save_format: Either `'tf'` or `'h5'`, indicating whether to save the\n",
      " |              model to Tensorflow SavedModel or HDF5. Defaults to 'tf' in TF 2.X,\n",
      " |              and 'h5' in TF 1.X.\n",
      " |          signatures: Signatures to save with the SavedModel. Applicable to the\n",
      " |              'tf' format only. Please see the `signatures` argument in\n",
      " |              `tf.saved_model.save` for details.\n",
      " |          options: (only applies to SavedModel format)\n",
      " |              `tf.saved_model.SaveOptions` object that specifies options for\n",
      " |              saving to SavedModel.\n",
      " |          save_traces: (only applies to SavedModel format) When enabled, the\n",
      " |              SavedModel will store the function traces for each layer. This\n",
      " |              can be disabled, so that only the configs of each layer are stored.\n",
      " |              Defaults to `True`. Disabling this will decrease serialization time\n",
      " |              and reduce file size, but it requires that all custom layers/models\n",
      " |              implement a `get_config()` method.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      from keras.models import load_model\n",
      " |      \n",
      " |      model.save('my_model.h5')  # creates a HDF5 file 'my_model.h5'\n",
      " |      del model  # deletes the existing model\n",
      " |      \n",
      " |      # returns a compiled model\n",
      " |      # identical to the previous one\n",
      " |      model = load_model('my_model.h5')\n",
      " |      ```\n",
      " |  \n",
      " |  save_weights(self, filepath, overwrite=True, save_format=None, options=None)\n",
      " |      Saves all layer weights.\n",
      " |      \n",
      " |      Either saves in HDF5 or in TensorFlow format based on the `save_format`\n",
      " |      argument.\n",
      " |      \n",
      " |      When saving in HDF5 format, the weight file has:\n",
      " |        - `layer_names` (attribute), a list of strings\n",
      " |            (ordered names of model layers).\n",
      " |        - For every layer, a `group` named `layer.name`\n",
      " |            - For every such layer group, a group attribute `weight_names`,\n",
      " |                a list of strings\n",
      " |                (ordered names of weights tensor of the layer).\n",
      " |            - For every weight in the layer, a dataset\n",
      " |                storing the weight value, named after the weight tensor.\n",
      " |      \n",
      " |      When saving in TensorFlow format, all objects referenced by the network are\n",
      " |      saved in the same format as `tf.train.Checkpoint`, including any `Layer`\n",
      " |      instances or `Optimizer` instances assigned to object attributes. For\n",
      " |      networks constructed from inputs and outputs using `tf.keras.Model(inputs,\n",
      " |      outputs)`, `Layer` instances used by the network are tracked/saved\n",
      " |      automatically. For user-defined classes which inherit from `tf.keras.Model`,\n",
      " |      `Layer` instances must be assigned to object attributes, typically in the\n",
      " |      constructor. See the documentation of `tf.train.Checkpoint` and\n",
      " |      `tf.keras.Model` for details.\n",
      " |      \n",
      " |      While the formats are the same, do not mix `save_weights` and\n",
      " |      `tf.train.Checkpoint`. Checkpoints saved by `Model.save_weights` should be\n",
      " |      loaded using `Model.load_weights`. Checkpoints saved using\n",
      " |      `tf.train.Checkpoint.save` should be restored using the corresponding\n",
      " |      `tf.train.Checkpoint.restore`. Prefer `tf.train.Checkpoint` over\n",
      " |      `save_weights` for training checkpoints.\n",
      " |      \n",
      " |      The TensorFlow format matches objects and variables by starting at a root\n",
      " |      object, `self` for `save_weights`, and greedily matching attribute\n",
      " |      names. For `Model.save` this is the `Model`, and for `Checkpoint.save` this\n",
      " |      is the `Checkpoint` even if the `Checkpoint` has a model attached. This\n",
      " |      means saving a `tf.keras.Model` using `save_weights` and loading into a\n",
      " |      `tf.train.Checkpoint` with a `Model` attached (or vice versa) will not match\n",
      " |      the `Model`'s variables. See the [guide to training\n",
      " |      checkpoints](https://www.tensorflow.org/guide/checkpoint) for details\n",
      " |      on the TensorFlow format.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          filepath: String or PathLike, path to the file to save the weights to.\n",
      " |              When saving in TensorFlow format, this is the prefix used for\n",
      " |              checkpoint files (multiple files are generated). Note that the '.h5'\n",
      " |              suffix causes weights to be saved in HDF5 format.\n",
      " |          overwrite: Whether to silently overwrite any existing file at the\n",
      " |              target location, or provide the user with a manual prompt.\n",
      " |          save_format: Either 'tf' or 'h5'. A `filepath` ending in '.h5' or\n",
      " |              '.keras' will default to HDF5 if `save_format` is `None`. Otherwise\n",
      " |              `None` defaults to 'tf'.\n",
      " |          options: Optional `tf.train.CheckpointOptions` object that specifies\n",
      " |              options for saving weights.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ImportError: If h5py is not available when attempting to save in HDF5\n",
      " |              format.\n",
      " |          ValueError: For invalid/unknown format arguments.\n",
      " |  \n",
      " |  summary(self, line_length=None, positions=None, print_fn=None)\n",
      " |      Prints a string summary of the network.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          line_length: Total length of printed lines\n",
      " |              (e.g. set this to adapt the display to different\n",
      " |              terminal window sizes).\n",
      " |          positions: Relative or absolute positions of log elements\n",
      " |              in each line. If not provided,\n",
      " |              defaults to `[.33, .55, .67, 1.]`.\n",
      " |          print_fn: Print function to use. Defaults to `print`.\n",
      " |              It will be called on each line of the summary.\n",
      " |              You can set it to a custom function\n",
      " |              in order to capture the string summary.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: if `summary()` is called before the model is built.\n",
      " |  \n",
      " |  test_on_batch(self, x, y=None, sample_weight=None, reset_metrics=True, return_dict=False)\n",
      " |      Test the model on a single batch of samples.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          x: Input data. It could be: - A Numpy array (or array-like), or a list\n",
      " |            of arrays (in case the model has multiple inputs). - A TensorFlow\n",
      " |            tensor, or a list of tensors (in case the model has multiple inputs).\n",
      " |            - A dict mapping input names to the corresponding array/tensors, if\n",
      " |            the model has named inputs.\n",
      " |          y: Target data. Like the input data `x`, it could be either Numpy\n",
      " |            array(s) or TensorFlow tensor(s). It should be consistent with `x`\n",
      " |            (you cannot have Numpy inputs and tensor targets, or inversely).\n",
      " |          sample_weight: Optional array of the same length as x, containing\n",
      " |            weights to apply to the model's loss for each sample. In the case of\n",
      " |            temporal data, you can pass a 2D array with shape (samples,\n",
      " |            sequence_length), to apply a different weight to every timestep of\n",
      " |            every sample.\n",
      " |          reset_metrics: If `True`, the metrics returned will be only for this\n",
      " |            batch. If `False`, the metrics will be statefully accumulated across\n",
      " |            batches.\n",
      " |          return_dict: If `True`, loss and metric results are returned as a dict,\n",
      " |            with each key being the name of the metric. If `False`, they are\n",
      " |            returned as a list.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Scalar test loss (if the model has a single output and no metrics)\n",
      " |          or list of scalars (if the model has multiple outputs\n",
      " |          and/or metrics). The attribute `model.metrics_names` will give you\n",
      " |          the display labels for the scalar outputs.\n",
      " |      \n",
      " |      Raises:\n",
      " |          RuntimeError: If `model.test_on_batch` is wrapped in `tf.function`.\n",
      " |          ValueError: In case of invalid user-provided arguments.\n",
      " |  \n",
      " |  test_step(self, data)\n",
      " |      The logic for one evaluation step.\n",
      " |      \n",
      " |      This method can be overridden to support custom evaluation logic.\n",
      " |      This method is called by `Model.make_test_function`.\n",
      " |      \n",
      " |      This function should contain the mathematical logic for one step of\n",
      " |      evaluation.\n",
      " |      This typically includes the forward pass, loss calculation, and metrics\n",
      " |      updates.\n",
      " |      \n",
      " |      Configuration details for *how* this logic is run (e.g. `tf.function` and\n",
      " |      `tf.distribute.Strategy` settings), should be left to\n",
      " |      `Model.make_test_function`, which can also be overridden.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        data: A nested structure of `Tensor`s.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A `dict` containing values that will be passed to\n",
      " |        `tf.keras.callbacks.CallbackList.on_train_batch_end`. Typically, the\n",
      " |        values of the `Model`'s metrics are returned.\n",
      " |  \n",
      " |  to_json(self, **kwargs)\n",
      " |      Returns a JSON string containing the network configuration.\n",
      " |      \n",
      " |      To load a network from a JSON save file, use\n",
      " |      `keras.models.model_from_json(json_string, custom_objects={})`.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          **kwargs: Additional keyword arguments\n",
      " |              to be passed to `json.dumps()`.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A JSON string.\n",
      " |  \n",
      " |  to_yaml(self, **kwargs)\n",
      " |      Returns a yaml string containing the network configuration.\n",
      " |      \n",
      " |      To load a network from a yaml save file, use\n",
      " |      `keras.models.model_from_yaml(yaml_string, custom_objects={})`.\n",
      " |      \n",
      " |      `custom_objects` should be a dictionary mapping\n",
      " |      the names of custom losses / layers / etc to the corresponding\n",
      " |      functions / classes.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          **kwargs: Additional keyword arguments\n",
      " |              to be passed to `yaml.dump()`.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A YAML string.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ImportError: if yaml module is not found.\n",
      " |  \n",
      " |  train_on_batch(self, x, y=None, sample_weight=None, class_weight=None, reset_metrics=True, return_dict=False)\n",
      " |      Runs a single gradient update on a single batch of data.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          x: Input data. It could be:\n",
      " |            - A Numpy array (or array-like), or a list of arrays\n",
      " |                (in case the model has multiple inputs).\n",
      " |            - A TensorFlow tensor, or a list of tensors\n",
      " |                (in case the model has multiple inputs).\n",
      " |            - A dict mapping input names to the corresponding array/tensors,\n",
      " |                if the model has named inputs.\n",
      " |          y: Target data. Like the input data `x`, it could be either Numpy\n",
      " |            array(s) or TensorFlow tensor(s). It should be consistent with `x`\n",
      " |            (you cannot have Numpy inputs and tensor targets, or inversely).\n",
      " |          sample_weight: Optional array of the same length as x, containing\n",
      " |            weights to apply to the model's loss for each sample. In the case of\n",
      " |            temporal data, you can pass a 2D array with shape (samples,\n",
      " |            sequence_length), to apply a different weight to every timestep of\n",
      " |            every sample.\n",
      " |          class_weight: Optional dictionary mapping class indices (integers) to a\n",
      " |            weight (float) to apply to the model's loss for the samples from this\n",
      " |            class during training. This can be useful to tell the model to \"pay\n",
      " |            more attention\" to samples from an under-represented class.\n",
      " |          reset_metrics: If `True`, the metrics returned will be only for this\n",
      " |            batch. If `False`, the metrics will be statefully accumulated across\n",
      " |            batches.\n",
      " |          return_dict: If `True`, loss and metric results are returned as a dict,\n",
      " |            with each key being the name of the metric. If `False`, they are\n",
      " |            returned as a list.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Scalar training loss\n",
      " |          (if the model has a single output and no metrics)\n",
      " |          or list of scalars (if the model has multiple outputs\n",
      " |          and/or metrics). The attribute `model.metrics_names` will give you\n",
      " |          the display labels for the scalar outputs.\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If `model.train_on_batch` is wrapped in `tf.function`.\n",
      " |        ValueError: In case of invalid user-provided arguments.\n",
      " |  \n",
      " |  train_step(self, data)\n",
      " |      The logic for one training step.\n",
      " |      \n",
      " |      This method can be overridden to support custom training logic.\n",
      " |      This method is called by `Model.make_train_function`.\n",
      " |      \n",
      " |      This method should contain the mathematical logic for one step of training.\n",
      " |      This typically includes the forward pass, loss calculation, backpropagation,\n",
      " |      and metric updates.\n",
      " |      \n",
      " |      Configuration details for *how* this logic is run (e.g. `tf.function` and\n",
      " |      `tf.distribute.Strategy` settings), should be left to\n",
      " |      `Model.make_train_function`, which can also be overridden.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        data: A nested structure of `Tensor`s.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A `dict` containing values that will be passed to\n",
      " |        `tf.keras.callbacks.CallbackList.on_train_batch_end`. Typically, the\n",
      " |        values of the `Model`'s metrics are returned. Example:\n",
      " |        `{'loss': 0.2, 'accuracy': 0.7}`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods inherited from tensorflow.python.keras.engine.training.Model:\n",
      " |  \n",
      " |  __new__(cls, *args, **kwargs)\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.keras.engine.training.Model:\n",
      " |  \n",
      " |  distribute_strategy\n",
      " |      The `tf.distribute.Strategy` this model was created under.\n",
      " |  \n",
      " |  metrics\n",
      " |      Returns the model's metrics added using `compile`, `add_metric` APIs.\n",
      " |      \n",
      " |      Note: Metrics passed to `compile()` are available only after a `keras.Model`\n",
      " |      has been trained/evaluated on actual data.\n",
      " |      \n",
      " |      Examples:\n",
      " |      \n",
      " |      >>> inputs = tf.keras.layers.Input(shape=(3,))\n",
      " |      >>> outputs = tf.keras.layers.Dense(2)(inputs)\n",
      " |      >>> model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
      " |      >>> model.compile(optimizer=\"Adam\", loss=\"mse\", metrics=[\"mae\"])\n",
      " |      >>> [m.name for m in model.metrics]\n",
      " |      []\n",
      " |      \n",
      " |      >>> x = np.random.random((2, 3))\n",
      " |      >>> y = np.random.randint(0, 2, (2, 2))\n",
      " |      >>> model.fit(x, y)\n",
      " |      >>> [m.name for m in model.metrics]\n",
      " |      ['loss', 'mae']\n",
      " |      \n",
      " |      >>> inputs = tf.keras.layers.Input(shape=(3,))\n",
      " |      >>> d = tf.keras.layers.Dense(2, name='out')\n",
      " |      >>> output_1 = d(inputs)\n",
      " |      >>> output_2 = d(inputs)\n",
      " |      >>> model = tf.keras.models.Model(\n",
      " |      ...    inputs=inputs, outputs=[output_1, output_2])\n",
      " |      >>> model.add_metric(\n",
      " |      ...    tf.reduce_sum(output_2), name='mean', aggregation='mean')\n",
      " |      >>> model.compile(optimizer=\"Adam\", loss=\"mse\", metrics=[\"mae\", \"acc\"])\n",
      " |      >>> model.fit(x, (y, y))\n",
      " |      >>> [m.name for m in model.metrics]\n",
      " |      ['loss', 'out_loss', 'out_1_loss', 'out_mae', 'out_acc', 'out_1_mae',\n",
      " |      'out_1_acc', 'mean']\n",
      " |  \n",
      " |  metrics_names\n",
      " |      Returns the model's display labels for all outputs.\n",
      " |      \n",
      " |      Note: `metrics_names` are available only after a `keras.Model` has been\n",
      " |      trained/evaluated on actual data.\n",
      " |      \n",
      " |      Examples:\n",
      " |      \n",
      " |      >>> inputs = tf.keras.layers.Input(shape=(3,))\n",
      " |      >>> outputs = tf.keras.layers.Dense(2)(inputs)\n",
      " |      >>> model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
      " |      >>> model.compile(optimizer=\"Adam\", loss=\"mse\", metrics=[\"mae\"])\n",
      " |      >>> model.metrics_names\n",
      " |      []\n",
      " |      \n",
      " |      >>> x = np.random.random((2, 3))\n",
      " |      >>> y = np.random.randint(0, 2, (2, 2))\n",
      " |      >>> model.fit(x, y)\n",
      " |      >>> model.metrics_names\n",
      " |      ['loss', 'mae']\n",
      " |      \n",
      " |      >>> inputs = tf.keras.layers.Input(shape=(3,))\n",
      " |      >>> d = tf.keras.layers.Dense(2, name='out')\n",
      " |      >>> output_1 = d(inputs)\n",
      " |      >>> output_2 = d(inputs)\n",
      " |      >>> model = tf.keras.models.Model(\n",
      " |      ...    inputs=inputs, outputs=[output_1, output_2])\n",
      " |      >>> model.compile(optimizer=\"Adam\", loss=\"mse\", metrics=[\"mae\", \"acc\"])\n",
      " |      >>> model.fit(x, (y, y))\n",
      " |      >>> model.metrics_names\n",
      " |      ['loss', 'out_loss', 'out_1_loss', 'out_mae', 'out_acc', 'out_1_mae',\n",
      " |      'out_1_acc']\n",
      " |  \n",
      " |  non_trainable_weights\n",
      " |      List of all non-trainable weights tracked by this layer.\n",
      " |      \n",
      " |      Non-trainable weights are *not* updated during training. They are expected\n",
      " |      to be updated manually in `call()`.\n",
      " |      \n",
      " |      Note: This will not track the weights of nested `tf.Modules` that are not\n",
      " |      themselves Keras layers.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of non-trainable variables.\n",
      " |  \n",
      " |  run_eagerly\n",
      " |      Settable attribute indicating whether the model should run eagerly.\n",
      " |      \n",
      " |      Running eagerly means that your model will be run step by step,\n",
      " |      like Python code. Your model might run slower, but it should become easier\n",
      " |      for you to debug it by stepping into individual layer calls.\n",
      " |      \n",
      " |      By default, we will attempt to compile your model to a static graph to\n",
      " |      deliver the best execution performance.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Boolean, whether the model should run eagerly.\n",
      " |  \n",
      " |  state_updates\n",
      " |      Deprecated, do NOT use!\n",
      " |      \n",
      " |      Returns the `updates` from all layers that are stateful.\n",
      " |      \n",
      " |      This is useful for separating training updates and\n",
      " |      state updates, e.g. when we need to update a layer's internal state\n",
      " |      during prediction.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A list of update ops.\n",
      " |  \n",
      " |  trainable_weights\n",
      " |      List of all trainable weights tracked by this layer.\n",
      " |      \n",
      " |      Trainable weights are updated via gradient descent during training.\n",
      " |      \n",
      " |      Note: This will not track the weights of nested `tf.Modules` that are not\n",
      " |      themselves Keras layers.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of trainable variables.\n",
      " |  \n",
      " |  weights\n",
      " |      Returns the list of all layer variables/weights.\n",
      " |      \n",
      " |      Note: This will not track the weights of nested `tf.Modules` that are not\n",
      " |      themselves Keras layers.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of variables.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from tensorflow.python.keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  __call__(self, *args, **kwargs)\n",
      " |      Wraps `call`, applying pre- and post-processing steps.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        *args: Positional arguments to be passed to `self.call`.\n",
      " |        **kwargs: Keyword arguments to be passed to `self.call`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Output tensor(s).\n",
      " |      \n",
      " |      Note:\n",
      " |        - The following optional keyword arguments are reserved for specific uses:\n",
      " |          * `training`: Boolean scalar tensor of Python boolean indicating\n",
      " |            whether the `call` is meant for training or inference.\n",
      " |          * `mask`: Boolean input mask.\n",
      " |        - If the layer's `call` method takes a `mask` argument (as some Keras\n",
      " |          layers do), its default value will be set to the mask generated\n",
      " |          for `inputs` by the previous layer (if `input` did come from\n",
      " |          a layer that generated a corresponding mask, i.e. if it came from\n",
      " |          a Keras layer with masking support.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: if the layer's `call` method returns None (an invalid value).\n",
      " |        RuntimeError: if `super().__init__()` was not called in the constructor.\n",
      " |  \n",
      " |  __delattr__(self, name)\n",
      " |      Implement delattr(self, name).\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  add_loss(self, losses, **kwargs)\n",
      " |      Add loss tensor(s), potentially dependent on layer inputs.\n",
      " |      \n",
      " |      Some losses (for instance, activity regularization losses) may be dependent\n",
      " |      on the inputs passed when calling a layer. Hence, when reusing the same\n",
      " |      layer on different inputs `a` and `b`, some entries in `layer.losses` may\n",
      " |      be dependent on `a` and some on `b`. This method automatically keeps track\n",
      " |      of dependencies.\n",
      " |      \n",
      " |      This method can be used inside a subclassed layer or model's `call`\n",
      " |      function, in which case `losses` should be a Tensor or list of Tensors.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      class MyLayer(tf.keras.layers.Layer):\n",
      " |        def call(self, inputs):\n",
      " |          self.add_loss(tf.abs(tf.reduce_mean(inputs)))\n",
      " |          return inputs\n",
      " |      ```\n",
      " |      \n",
      " |      This method can also be called directly on a Functional Model during\n",
      " |      construction. In this case, any loss Tensors passed to this Model must\n",
      " |      be symbolic and be able to be traced back to the model's `Input`s. These\n",
      " |      losses become part of the model's topology and are tracked in `get_config`.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      # Activity regularization.\n",
      " |      model.add_loss(tf.abs(tf.reduce_mean(x)))\n",
      " |      ```\n",
      " |      \n",
      " |      If this is not the case for your loss (if, for example, your loss references\n",
      " |      a `Variable` of one of the model's layers), you can wrap your loss in a\n",
      " |      zero-argument lambda. These losses are not tracked as part of the model's\n",
      " |      topology since they can't be serialized.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      d = tf.keras.layers.Dense(10)\n",
      " |      x = d(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      # Weight regularization.\n",
      " |      model.add_loss(lambda: tf.reduce_mean(d.kernel))\n",
      " |      ```\n",
      " |      \n",
      " |      Arguments:\n",
      " |        losses: Loss tensor, or list/tuple of tensors. Rather than tensors, losses\n",
      " |          may also be zero-argument callables which create a loss tensor.\n",
      " |        **kwargs: Additional keyword arguments for backward compatibility.\n",
      " |          Accepted values:\n",
      " |            inputs - Deprecated, will be automatically inferred.\n",
      " |  \n",
      " |  add_metric(self, value, name=None, **kwargs)\n",
      " |      Adds metric tensor to the layer.\n",
      " |      \n",
      " |      This method can be used inside the `call()` method of a subclassed layer\n",
      " |      or model.\n",
      " |      \n",
      " |      ```python\n",
      " |      class MyMetricLayer(tf.keras.layers.Layer):\n",
      " |        def __init__(self):\n",
      " |          super(MyMetricLayer, self).__init__(name='my_metric_layer')\n",
      " |          self.mean = tf.keras.metrics.Mean(name='metric_1')\n",
      " |      \n",
      " |        def call(self, inputs):\n",
      " |          self.add_metric(self.mean(x))\n",
      " |          self.add_metric(tf.reduce_sum(x), name='metric_2')\n",
      " |          return inputs\n",
      " |      ```\n",
      " |      \n",
      " |      This method can also be called directly on a Functional Model during\n",
      " |      construction. In this case, any tensor passed to this Model must\n",
      " |      be symbolic and be able to be traced back to the model's `Input`s. These\n",
      " |      metrics become part of the model's topology and are tracked when you\n",
      " |      save the model via `save()`.\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      model.add_metric(math_ops.reduce_sum(x), name='metric_1')\n",
      " |      ```\n",
      " |      \n",
      " |      Note: Calling `add_metric()` with the result of a metric object on a\n",
      " |      Functional Model, as shown in the example below, is not supported. This is\n",
      " |      because we cannot trace the metric result tensor back to the model's inputs.\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      model.add_metric(tf.keras.metrics.Mean()(x), name='metric_1')\n",
      " |      ```\n",
      " |      \n",
      " |      Args:\n",
      " |        value: Metric tensor.\n",
      " |        name: String metric name.\n",
      " |        **kwargs: Additional keyword arguments for backward compatibility.\n",
      " |          Accepted values:\n",
      " |          `aggregation` - When the `value` tensor provided is not the result of\n",
      " |          calling a `keras.Metric` instance, it will be aggregated by default\n",
      " |          using a `keras.Metric.Mean`.\n",
      " |  \n",
      " |  add_update(self, updates, inputs=None)\n",
      " |      Add update op(s), potentially dependent on layer inputs.\n",
      " |      \n",
      " |      Weight updates (for instance, the updates of the moving mean and variance\n",
      " |      in a BatchNormalization layer) may be dependent on the inputs passed\n",
      " |      when calling a layer. Hence, when reusing the same layer on\n",
      " |      different inputs `a` and `b`, some entries in `layer.updates` may be\n",
      " |      dependent on `a` and some on `b`. This method automatically keeps track\n",
      " |      of dependencies.\n",
      " |      \n",
      " |      This call is ignored when eager execution is enabled (in that case, variable\n",
      " |      updates are run on the fly and thus do not need to be tracked for later\n",
      " |      execution).\n",
      " |      \n",
      " |      Arguments:\n",
      " |        updates: Update op, or list/tuple of update ops, or zero-arg callable\n",
      " |          that returns an update op. A zero-arg callable should be passed in\n",
      " |          order to disable running the updates by setting `trainable=False`\n",
      " |          on this Layer, when executing in Eager mode.\n",
      " |        inputs: Deprecated, will be automatically inferred.\n",
      " |  \n",
      " |  add_variable(self, *args, **kwargs)\n",
      " |      Deprecated, do NOT use! Alias for `add_weight`.\n",
      " |  \n",
      " |  add_weight(self, name=None, shape=None, dtype=None, initializer=None, regularizer=None, trainable=None, constraint=None, use_resource=None, synchronization=<VariableSynchronization.AUTO: 0>, aggregation=<VariableAggregation.NONE: 0>, **kwargs)\n",
      " |      Adds a new variable to the layer.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        name: Variable name.\n",
      " |        shape: Variable shape. Defaults to scalar if unspecified.\n",
      " |        dtype: The type of the variable. Defaults to `self.dtype`.\n",
      " |        initializer: Initializer instance (callable).\n",
      " |        regularizer: Regularizer instance (callable).\n",
      " |        trainable: Boolean, whether the variable should be part of the layer's\n",
      " |          \"trainable_variables\" (e.g. variables, biases)\n",
      " |          or \"non_trainable_variables\" (e.g. BatchNorm mean and variance).\n",
      " |          Note that `trainable` cannot be `True` if `synchronization`\n",
      " |          is set to `ON_READ`.\n",
      " |        constraint: Constraint instance (callable).\n",
      " |        use_resource: Whether to use `ResourceVariable`.\n",
      " |        synchronization: Indicates when a distributed a variable will be\n",
      " |          aggregated. Accepted values are constants defined in the class\n",
      " |          `tf.VariableSynchronization`. By default the synchronization is set to\n",
      " |          `AUTO` and the current `DistributionStrategy` chooses\n",
      " |          when to synchronize. If `synchronization` is set to `ON_READ`,\n",
      " |          `trainable` must not be set to `True`.\n",
      " |        aggregation: Indicates how a distributed variable will be aggregated.\n",
      " |          Accepted values are constants defined in the class\n",
      " |          `tf.VariableAggregation`.\n",
      " |        **kwargs: Additional keyword arguments. Accepted values are `getter`,\n",
      " |          `collections`, `experimental_autocast` and `caching_device`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The variable created.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: When giving unsupported dtype and no initializer or when\n",
      " |          trainable has been set to True with synchronization set as `ON_READ`.\n",
      " |  \n",
      " |  apply(self, inputs, *args, **kwargs)\n",
      " |      Deprecated, do NOT use!\n",
      " |      \n",
      " |      This is an alias of `self.__call__`.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        inputs: Input tensor(s).\n",
      " |        *args: additional positional arguments to be passed to `self.call`.\n",
      " |        **kwargs: additional keyword arguments to be passed to `self.call`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Output tensor(s).\n",
      " |  \n",
      " |  compute_output_signature(self, input_signature)\n",
      " |      Compute the output tensor signature of the layer based on the inputs.\n",
      " |      \n",
      " |      Unlike a TensorShape object, a TensorSpec object contains both shape\n",
      " |      and dtype information for a tensor. This method allows layers to provide\n",
      " |      output dtype information if it is different from the input dtype.\n",
      " |      For any layer that doesn't implement this function,\n",
      " |      the framework will fall back to use `compute_output_shape`, and will\n",
      " |      assume that the output dtype matches the input dtype.\n",
      " |      \n",
      " |      Args:\n",
      " |        input_signature: Single TensorSpec or nested structure of TensorSpec\n",
      " |          objects, describing a candidate input for the layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Single TensorSpec or nested structure of TensorSpec objects, describing\n",
      " |          how the layer would transform the provided input.\n",
      " |      \n",
      " |      Raises:\n",
      " |        TypeError: If input_signature contains a non-TensorSpec object.\n",
      " |  \n",
      " |  count_params(self)\n",
      " |      Count the total number of scalars composing the weights.\n",
      " |      \n",
      " |      Returns:\n",
      " |          An integer count.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: if the layer isn't yet built\n",
      " |            (in which case its weights aren't yet defined).\n",
      " |  \n",
      " |  get_input_at(self, node_index)\n",
      " |      Retrieves the input tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tensor (or list of tensors if the layer has multiple inputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_input_mask_at(self, node_index)\n",
      " |      Retrieves the input mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple inputs).\n",
      " |  \n",
      " |  get_input_shape_at(self, node_index)\n",
      " |      Retrieves the input shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple inputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_losses_for(self, inputs)\n",
      " |      Deprecated, do NOT use!\n",
      " |      \n",
      " |      Retrieves losses relevant to a specific set of inputs.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        inputs: Input tensor or list/tuple of input tensors.\n",
      " |      \n",
      " |      Returns:\n",
      " |        List of loss tensors of the layer that depend on `inputs`.\n",
      " |  \n",
      " |  get_output_at(self, node_index)\n",
      " |      Retrieves the output tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tensor (or list of tensors if the layer has multiple outputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_output_mask_at(self, node_index)\n",
      " |      Retrieves the output mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple outputs).\n",
      " |  \n",
      " |  get_output_shape_at(self, node_index)\n",
      " |      Retrieves the output shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple outputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_updates_for(self, inputs)\n",
      " |      Deprecated, do NOT use!\n",
      " |      \n",
      " |      Retrieves updates relevant to a specific set of inputs.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        inputs: Input tensor or list/tuple of input tensors.\n",
      " |      \n",
      " |      Returns:\n",
      " |        List of update ops of the layer that depend on `inputs`.\n",
      " |  \n",
      " |  set_weights(self, weights)\n",
      " |      Sets the weights of the layer, from Numpy arrays.\n",
      " |      \n",
      " |      The weights of a layer represent the state of the layer. This function\n",
      " |      sets the weight values from numpy arrays. The weight values should be\n",
      " |      passed in the order they are created by the layer. Note that the layer's\n",
      " |      weights must be instantiated before calling this function by calling\n",
      " |      the layer.\n",
      " |      \n",
      " |      For example, a Dense layer returns a list of two values-- per-output\n",
      " |      weights and the bias value. These can be used to set the weights of another\n",
      " |      Dense layer:\n",
      " |      \n",
      " |      >>> a = tf.keras.layers.Dense(1,\n",
      " |      ...   kernel_initializer=tf.constant_initializer(1.))\n",
      " |      >>> a_out = a(tf.convert_to_tensor([[1., 2., 3.]]))\n",
      " |      >>> a.get_weights()\n",
      " |      [array([[1.],\n",
      " |             [1.],\n",
      " |             [1.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      >>> b = tf.keras.layers.Dense(1,\n",
      " |      ...   kernel_initializer=tf.constant_initializer(2.))\n",
      " |      >>> b_out = b(tf.convert_to_tensor([[10., 20., 30.]]))\n",
      " |      >>> b.get_weights()\n",
      " |      [array([[2.],\n",
      " |             [2.],\n",
      " |             [2.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      >>> b.set_weights(a.get_weights())\n",
      " |      >>> b.get_weights()\n",
      " |      [array([[1.],\n",
      " |             [1.],\n",
      " |             [1.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      \n",
      " |      Arguments:\n",
      " |          weights: a list of Numpy arrays. The number\n",
      " |              of arrays and their shape must match\n",
      " |              number of the dimensions of the weights\n",
      " |              of the layer (i.e. it should match the\n",
      " |              output of `get_weights`).\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: If the provided weights list does not match the\n",
      " |              layer's specifications.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  activity_regularizer\n",
      " |      Optional regularizer function for the output of this layer.\n",
      " |  \n",
      " |  compute_dtype\n",
      " |      The dtype of the layer's computations.\n",
      " |      \n",
      " |      This is equivalent to `Layer.dtype_policy.compute_dtype`. Unless\n",
      " |      mixed precision is used, this is the same as `Layer.dtype`, the dtype of\n",
      " |      the weights.\n",
      " |      \n",
      " |      Layers automatically cast their inputs to the compute dtype, which causes\n",
      " |      computations and the output to be in the compute dtype as well. This is done\n",
      " |      by the base Layer class in `Layer.__call__`, so you do not have to insert\n",
      " |      these casts if implementing your own layer.\n",
      " |      \n",
      " |      Layers often perform certain internal computations in higher precision when\n",
      " |      `compute_dtype` is float16 or bfloat16 for numeric stability. The output\n",
      " |      will still typically be float16 or bfloat16 in such cases.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The layer's compute dtype.\n",
      " |  \n",
      " |  dtype\n",
      " |      The dtype of the layer weights.\n",
      " |      \n",
      " |      This is equivalent to `Layer.dtype_policy.variable_dtype`. Unless\n",
      " |      mixed precision is used, this is the same as `Layer.compute_dtype`, the\n",
      " |      dtype of the layer's computations.\n",
      " |  \n",
      " |  dtype_policy\n",
      " |      The dtype policy associated with this layer.\n",
      " |      \n",
      " |      This is an instance of a `tf.keras.mixed_precision.Policy`.\n",
      " |  \n",
      " |  dynamic\n",
      " |      Whether the layer is dynamic (eager-only); set in the constructor.\n",
      " |  \n",
      " |  inbound_nodes\n",
      " |      Deprecated, do NOT use! Only for compatibility with external Keras.\n",
      " |  \n",
      " |  input_mask\n",
      " |      Retrieves the input mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input mask tensor (potentially None) or list of input\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  losses\n",
      " |      List of losses added using the `add_loss()` API.\n",
      " |      \n",
      " |      Variable regularization tensors are created when this property is accessed,\n",
      " |      so it is eager safe: accessing `losses` under a `tf.GradientTape` will\n",
      " |      propagate gradients back to the corresponding variables.\n",
      " |      \n",
      " |      Examples:\n",
      " |      \n",
      " |      >>> class MyLayer(tf.keras.layers.Layer):\n",
      " |      ...   def call(self, inputs):\n",
      " |      ...     self.add_loss(tf.abs(tf.reduce_mean(inputs)))\n",
      " |      ...     return inputs\n",
      " |      >>> l = MyLayer()\n",
      " |      >>> l(np.ones((10, 1)))\n",
      " |      >>> l.losses\n",
      " |      [1.0]\n",
      " |      \n",
      " |      >>> inputs = tf.keras.Input(shape=(10,))\n",
      " |      >>> x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      >>> outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      >>> model = tf.keras.Model(inputs, outputs)\n",
      " |      >>> # Activity regularization.\n",
      " |      >>> len(model.losses)\n",
      " |      0\n",
      " |      >>> model.add_loss(tf.abs(tf.reduce_mean(x)))\n",
      " |      >>> len(model.losses)\n",
      " |      1\n",
      " |      \n",
      " |      >>> inputs = tf.keras.Input(shape=(10,))\n",
      " |      >>> d = tf.keras.layers.Dense(10, kernel_initializer='ones')\n",
      " |      >>> x = d(inputs)\n",
      " |      >>> outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      >>> model = tf.keras.Model(inputs, outputs)\n",
      " |      >>> # Weight regularization.\n",
      " |      >>> model.add_loss(lambda: tf.reduce_mean(d.kernel))\n",
      " |      >>> model.losses\n",
      " |      [<tf.Tensor: shape=(), dtype=float32, numpy=1.0>]\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of tensors.\n",
      " |  \n",
      " |  name\n",
      " |      Name of the layer (string), set in the constructor.\n",
      " |  \n",
      " |  non_trainable_variables\n",
      " |  \n",
      " |  outbound_nodes\n",
      " |      Deprecated, do NOT use! Only for compatibility with external Keras.\n",
      " |  \n",
      " |  output_mask\n",
      " |      Retrieves the output mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Output mask tensor (potentially None) or list of output\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  stateful\n",
      " |  \n",
      " |  supports_masking\n",
      " |      Whether this layer supports computing a mask using `compute_mask`.\n",
      " |  \n",
      " |  trainable\n",
      " |  \n",
      " |  trainable_variables\n",
      " |      Sequence of trainable variables owned by this module and its submodules.\n",
      " |      \n",
      " |      Note: this method uses reflection to find variables on the current instance\n",
      " |      and submodules. For performance reasons you may wish to cache the result\n",
      " |      of calling this method if you don't expect the return value to change.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of variables for the current module (sorted by attribute\n",
      " |        name) followed by variables from all submodules recursively (breadth\n",
      " |        first).\n",
      " |  \n",
      " |  updates\n",
      " |  \n",
      " |  variable_dtype\n",
      " |      Alias of `Layer.dtype`, the dtype of the weights.\n",
      " |  \n",
      " |  variables\n",
      " |      Returns the list of all layer variables/weights.\n",
      " |      \n",
      " |      Alias of `self.weights`.\n",
      " |      \n",
      " |      Note: This will not track the weights of nested `tf.Modules` that are not\n",
      " |      themselves Keras layers.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of variables.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from tensorflow.python.module.module.Module:\n",
      " |  \n",
      " |  with_name_scope(method) from builtins.type\n",
      " |      Decorator to automatically enter the module name scope.\n",
      " |      \n",
      " |      >>> class MyModule(tf.Module):\n",
      " |      ...   @tf.Module.with_name_scope\n",
      " |      ...   def __call__(self, x):\n",
      " |      ...     if not hasattr(self, 'w'):\n",
      " |      ...       self.w = tf.Variable(tf.random.normal([x.shape[1], 3]))\n",
      " |      ...     return tf.matmul(x, self.w)\n",
      " |      \n",
      " |      Using the above module would produce `tf.Variable`s and `tf.Tensor`s whose\n",
      " |      names included the module name:\n",
      " |      \n",
      " |      >>> mod = MyModule()\n",
      " |      >>> mod(tf.ones([1, 2]))\n",
      " |      <tf.Tensor: shape=(1, 3), dtype=float32, numpy=..., dtype=float32)>\n",
      " |      >>> mod.w\n",
      " |      <tf.Variable 'my_module/Variable:0' shape=(2, 3) dtype=float32,\n",
      " |      numpy=..., dtype=float32)>\n",
      " |      \n",
      " |      Args:\n",
      " |        method: The method to wrap.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The original method wrapped such that it enters the module's name scope.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.module.module.Module:\n",
      " |  \n",
      " |  name_scope\n",
      " |      Returns a `tf.name_scope` instance for this class.\n",
      " |  \n",
      " |  submodules\n",
      " |      Sequence of all sub-modules.\n",
      " |      \n",
      " |      Submodules are modules which are properties of this module, or found as\n",
      " |      properties of modules which are properties of this module (and so on).\n",
      " |      \n",
      " |      >>> a = tf.Module()\n",
      " |      >>> b = tf.Module()\n",
      " |      >>> c = tf.Module()\n",
      " |      >>> a.b = b\n",
      " |      >>> b.c = c\n",
      " |      >>> list(a.submodules) == [b, c]\n",
      " |      True\n",
      " |      >>> list(b.submodules) == [c]\n",
      " |      True\n",
      " |      >>> list(c.submodules) == []\n",
      " |      True\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of all submodules.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.training.tracking.base.Trackable:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(Sequential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "anticipated-investment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Dense in module tensorflow.python.keras.layers.core:\n",
      "\n",
      "class Dense(tensorflow.python.keras.engine.base_layer.Layer)\n",
      " |  Dense(*args, **kwargs)\n",
      " |  \n",
      " |  Just your regular densely-connected NN layer.\n",
      " |  \n",
      " |  `Dense` implements the operation:\n",
      " |  `output = activation(dot(input, kernel) + bias)`\n",
      " |  where `activation` is the element-wise activation function\n",
      " |  passed as the `activation` argument, `kernel` is a weights matrix\n",
      " |  created by the layer, and `bias` is a bias vector created by the layer\n",
      " |  (only applicable if `use_bias` is `True`).\n",
      " |  \n",
      " |  Note: If the input to the layer has a rank greater than 2, then `Dense`\n",
      " |  computes the dot product between the `inputs` and the `kernel` along the\n",
      " |  last axis of the `inputs` and axis 1 of the `kernel` (using `tf.tensordot`).\n",
      " |  For example, if input has dimensions `(batch_size, d0, d1)`,\n",
      " |  then we create a `kernel` with shape `(d1, units)`, and the `kernel` operates\n",
      " |  along axis 2 of the `input`, on every sub-tensor of shape `(1, 1, d1)`\n",
      " |  (there are `batch_size * d0` such sub-tensors).\n",
      " |  The output in this case will have shape `(batch_size, d0, units)`.\n",
      " |  \n",
      " |  Besides, layer attributes cannot be modified after the layer has been called\n",
      " |  once (except the `trainable` attribute).\n",
      " |  \n",
      " |  Example:\n",
      " |  \n",
      " |  >>> # Create a `Sequential` model and add a Dense layer as the first layer.\n",
      " |  >>> model = tf.keras.models.Sequential()\n",
      " |  >>> model.add(tf.keras.Input(shape=(16,)))\n",
      " |  >>> model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
      " |  >>> # Now the model will take as input arrays of shape (None, 16)\n",
      " |  >>> # and output arrays of shape (None, 32).\n",
      " |  >>> # Note that after the first layer, you don't need to specify\n",
      " |  >>> # the size of the input anymore:\n",
      " |  >>> model.add(tf.keras.layers.Dense(32))\n",
      " |  >>> model.output_shape\n",
      " |  (None, 32)\n",
      " |  \n",
      " |  Arguments:\n",
      " |    units: Positive integer, dimensionality of the output space.\n",
      " |    activation: Activation function to use.\n",
      " |      If you don't specify anything, no activation is applied\n",
      " |      (ie. \"linear\" activation: `a(x) = x`).\n",
      " |    use_bias: Boolean, whether the layer uses a bias vector.\n",
      " |    kernel_initializer: Initializer for the `kernel` weights matrix.\n",
      " |    bias_initializer: Initializer for the bias vector.\n",
      " |    kernel_regularizer: Regularizer function applied to\n",
      " |      the `kernel` weights matrix.\n",
      " |    bias_regularizer: Regularizer function applied to the bias vector.\n",
      " |    activity_regularizer: Regularizer function applied to\n",
      " |      the output of the layer (its \"activation\").\n",
      " |    kernel_constraint: Constraint function applied to\n",
      " |      the `kernel` weights matrix.\n",
      " |    bias_constraint: Constraint function applied to the bias vector.\n",
      " |  \n",
      " |  Input shape:\n",
      " |    N-D tensor with shape: `(batch_size, ..., input_dim)`.\n",
      " |    The most common situation would be\n",
      " |    a 2D input with shape `(batch_size, input_dim)`.\n",
      " |  \n",
      " |  Output shape:\n",
      " |    N-D tensor with shape: `(batch_size, ..., units)`.\n",
      " |    For instance, for a 2D input with shape `(batch_size, input_dim)`,\n",
      " |    the output would have shape `(batch_size, units)`.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Dense\n",
      " |      tensorflow.python.keras.engine.base_layer.Layer\n",
      " |      tensorflow.python.module.module.Module\n",
      " |      tensorflow.python.training.tracking.tracking.AutoTrackable\n",
      " |      tensorflow.python.training.tracking.base.Trackable\n",
      " |      tensorflow.python.keras.utils.version_utils.LayerVersionSelector\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, units, activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None, **kwargs)\n",
      " |  \n",
      " |  build(self, input_shape)\n",
      " |      Creates the variables of the layer (optional, for subclass implementers).\n",
      " |      \n",
      " |      This is a method that implementers of subclasses of `Layer` or `Model`\n",
      " |      can override if they need a state-creation step in-between\n",
      " |      layer instantiation and layer call.\n",
      " |      \n",
      " |      This is typically used to create the weights of `Layer` subclasses.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        input_shape: Instance of `TensorShape`, or list of instances of\n",
      " |          `TensorShape` if the layer expects a list of inputs\n",
      " |          (one instance per input).\n",
      " |  \n",
      " |  call(self, inputs)\n",
      " |      This is where the layer's logic lives.\n",
      " |      \n",
      " |      Note here that `call()` method in `tf.keras` is little bit different\n",
      " |      from `keras` API. In `keras` API, you can pass support masking for\n",
      " |      layers as additional arguments. Whereas `tf.keras` has `compute_mask()`\n",
      " |      method to support masking.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          inputs: Input tensor, or list/tuple of input tensors.\n",
      " |          **kwargs: Additional keyword arguments. Currently unused.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tensor or list/tuple of tensors.\n",
      " |  \n",
      " |  compute_output_shape(self, input_shape)\n",
      " |      Computes the output shape of the layer.\n",
      " |      \n",
      " |      If the layer has not been built, this method will call `build` on the\n",
      " |      layer. This assumes that the layer will later be used with inputs that\n",
      " |      match the input shape provided here.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          input_shape: Shape tuple (tuple of integers)\n",
      " |              or list of shape tuples (one per output tensor of the layer).\n",
      " |              Shape tuples can include None for free dimensions,\n",
      " |              instead of an integer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          An input shape tuple.\n",
      " |  \n",
      " |  get_config(self)\n",
      " |      Returns the config of the layer.\n",
      " |      \n",
      " |      A layer config is a Python dictionary (serializable)\n",
      " |      containing the configuration of a layer.\n",
      " |      The same layer can be reinstantiated later\n",
      " |      (without its trained weights) from this configuration.\n",
      " |      \n",
      " |      The config of a layer does not include connectivity\n",
      " |      information, nor the layer class name. These are handled\n",
      " |      by `Network` (one layer of abstraction above).\n",
      " |      \n",
      " |      Returns:\n",
      " |          Python dictionary.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from tensorflow.python.keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  __call__(self, *args, **kwargs)\n",
      " |      Wraps `call`, applying pre- and post-processing steps.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        *args: Positional arguments to be passed to `self.call`.\n",
      " |        **kwargs: Keyword arguments to be passed to `self.call`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Output tensor(s).\n",
      " |      \n",
      " |      Note:\n",
      " |        - The following optional keyword arguments are reserved for specific uses:\n",
      " |          * `training`: Boolean scalar tensor of Python boolean indicating\n",
      " |            whether the `call` is meant for training or inference.\n",
      " |          * `mask`: Boolean input mask.\n",
      " |        - If the layer's `call` method takes a `mask` argument (as some Keras\n",
      " |          layers do), its default value will be set to the mask generated\n",
      " |          for `inputs` by the previous layer (if `input` did come from\n",
      " |          a layer that generated a corresponding mask, i.e. if it came from\n",
      " |          a Keras layer with masking support.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: if the layer's `call` method returns None (an invalid value).\n",
      " |        RuntimeError: if `super().__init__()` was not called in the constructor.\n",
      " |  \n",
      " |  __delattr__(self, name)\n",
      " |      Implement delattr(self, name).\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __setattr__(self, name, value)\n",
      " |      Support self.foo = trackable syntax.\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  add_loss(self, losses, **kwargs)\n",
      " |      Add loss tensor(s), potentially dependent on layer inputs.\n",
      " |      \n",
      " |      Some losses (for instance, activity regularization losses) may be dependent\n",
      " |      on the inputs passed when calling a layer. Hence, when reusing the same\n",
      " |      layer on different inputs `a` and `b`, some entries in `layer.losses` may\n",
      " |      be dependent on `a` and some on `b`. This method automatically keeps track\n",
      " |      of dependencies.\n",
      " |      \n",
      " |      This method can be used inside a subclassed layer or model's `call`\n",
      " |      function, in which case `losses` should be a Tensor or list of Tensors.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      class MyLayer(tf.keras.layers.Layer):\n",
      " |        def call(self, inputs):\n",
      " |          self.add_loss(tf.abs(tf.reduce_mean(inputs)))\n",
      " |          return inputs\n",
      " |      ```\n",
      " |      \n",
      " |      This method can also be called directly on a Functional Model during\n",
      " |      construction. In this case, any loss Tensors passed to this Model must\n",
      " |      be symbolic and be able to be traced back to the model's `Input`s. These\n",
      " |      losses become part of the model's topology and are tracked in `get_config`.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      # Activity regularization.\n",
      " |      model.add_loss(tf.abs(tf.reduce_mean(x)))\n",
      " |      ```\n",
      " |      \n",
      " |      If this is not the case for your loss (if, for example, your loss references\n",
      " |      a `Variable` of one of the model's layers), you can wrap your loss in a\n",
      " |      zero-argument lambda. These losses are not tracked as part of the model's\n",
      " |      topology since they can't be serialized.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      d = tf.keras.layers.Dense(10)\n",
      " |      x = d(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      # Weight regularization.\n",
      " |      model.add_loss(lambda: tf.reduce_mean(d.kernel))\n",
      " |      ```\n",
      " |      \n",
      " |      Arguments:\n",
      " |        losses: Loss tensor, or list/tuple of tensors. Rather than tensors, losses\n",
      " |          may also be zero-argument callables which create a loss tensor.\n",
      " |        **kwargs: Additional keyword arguments for backward compatibility.\n",
      " |          Accepted values:\n",
      " |            inputs - Deprecated, will be automatically inferred.\n",
      " |  \n",
      " |  add_metric(self, value, name=None, **kwargs)\n",
      " |      Adds metric tensor to the layer.\n",
      " |      \n",
      " |      This method can be used inside the `call()` method of a subclassed layer\n",
      " |      or model.\n",
      " |      \n",
      " |      ```python\n",
      " |      class MyMetricLayer(tf.keras.layers.Layer):\n",
      " |        def __init__(self):\n",
      " |          super(MyMetricLayer, self).__init__(name='my_metric_layer')\n",
      " |          self.mean = tf.keras.metrics.Mean(name='metric_1')\n",
      " |      \n",
      " |        def call(self, inputs):\n",
      " |          self.add_metric(self.mean(x))\n",
      " |          self.add_metric(tf.reduce_sum(x), name='metric_2')\n",
      " |          return inputs\n",
      " |      ```\n",
      " |      \n",
      " |      This method can also be called directly on a Functional Model during\n",
      " |      construction. In this case, any tensor passed to this Model must\n",
      " |      be symbolic and be able to be traced back to the model's `Input`s. These\n",
      " |      metrics become part of the model's topology and are tracked when you\n",
      " |      save the model via `save()`.\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      model.add_metric(math_ops.reduce_sum(x), name='metric_1')\n",
      " |      ```\n",
      " |      \n",
      " |      Note: Calling `add_metric()` with the result of a metric object on a\n",
      " |      Functional Model, as shown in the example below, is not supported. This is\n",
      " |      because we cannot trace the metric result tensor back to the model's inputs.\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      model.add_metric(tf.keras.metrics.Mean()(x), name='metric_1')\n",
      " |      ```\n",
      " |      \n",
      " |      Args:\n",
      " |        value: Metric tensor.\n",
      " |        name: String metric name.\n",
      " |        **kwargs: Additional keyword arguments for backward compatibility.\n",
      " |          Accepted values:\n",
      " |          `aggregation` - When the `value` tensor provided is not the result of\n",
      " |          calling a `keras.Metric` instance, it will be aggregated by default\n",
      " |          using a `keras.Metric.Mean`.\n",
      " |  \n",
      " |  add_update(self, updates, inputs=None)\n",
      " |      Add update op(s), potentially dependent on layer inputs.\n",
      " |      \n",
      " |      Weight updates (for instance, the updates of the moving mean and variance\n",
      " |      in a BatchNormalization layer) may be dependent on the inputs passed\n",
      " |      when calling a layer. Hence, when reusing the same layer on\n",
      " |      different inputs `a` and `b`, some entries in `layer.updates` may be\n",
      " |      dependent on `a` and some on `b`. This method automatically keeps track\n",
      " |      of dependencies.\n",
      " |      \n",
      " |      This call is ignored when eager execution is enabled (in that case, variable\n",
      " |      updates are run on the fly and thus do not need to be tracked for later\n",
      " |      execution).\n",
      " |      \n",
      " |      Arguments:\n",
      " |        updates: Update op, or list/tuple of update ops, or zero-arg callable\n",
      " |          that returns an update op. A zero-arg callable should be passed in\n",
      " |          order to disable running the updates by setting `trainable=False`\n",
      " |          on this Layer, when executing in Eager mode.\n",
      " |        inputs: Deprecated, will be automatically inferred.\n",
      " |  \n",
      " |  add_variable(self, *args, **kwargs)\n",
      " |      Deprecated, do NOT use! Alias for `add_weight`.\n",
      " |  \n",
      " |  add_weight(self, name=None, shape=None, dtype=None, initializer=None, regularizer=None, trainable=None, constraint=None, use_resource=None, synchronization=<VariableSynchronization.AUTO: 0>, aggregation=<VariableAggregation.NONE: 0>, **kwargs)\n",
      " |      Adds a new variable to the layer.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        name: Variable name.\n",
      " |        shape: Variable shape. Defaults to scalar if unspecified.\n",
      " |        dtype: The type of the variable. Defaults to `self.dtype`.\n",
      " |        initializer: Initializer instance (callable).\n",
      " |        regularizer: Regularizer instance (callable).\n",
      " |        trainable: Boolean, whether the variable should be part of the layer's\n",
      " |          \"trainable_variables\" (e.g. variables, biases)\n",
      " |          or \"non_trainable_variables\" (e.g. BatchNorm mean and variance).\n",
      " |          Note that `trainable` cannot be `True` if `synchronization`\n",
      " |          is set to `ON_READ`.\n",
      " |        constraint: Constraint instance (callable).\n",
      " |        use_resource: Whether to use `ResourceVariable`.\n",
      " |        synchronization: Indicates when a distributed a variable will be\n",
      " |          aggregated. Accepted values are constants defined in the class\n",
      " |          `tf.VariableSynchronization`. By default the synchronization is set to\n",
      " |          `AUTO` and the current `DistributionStrategy` chooses\n",
      " |          when to synchronize. If `synchronization` is set to `ON_READ`,\n",
      " |          `trainable` must not be set to `True`.\n",
      " |        aggregation: Indicates how a distributed variable will be aggregated.\n",
      " |          Accepted values are constants defined in the class\n",
      " |          `tf.VariableAggregation`.\n",
      " |        **kwargs: Additional keyword arguments. Accepted values are `getter`,\n",
      " |          `collections`, `experimental_autocast` and `caching_device`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The variable created.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: When giving unsupported dtype and no initializer or when\n",
      " |          trainable has been set to True with synchronization set as `ON_READ`.\n",
      " |  \n",
      " |  apply(self, inputs, *args, **kwargs)\n",
      " |      Deprecated, do NOT use!\n",
      " |      \n",
      " |      This is an alias of `self.__call__`.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        inputs: Input tensor(s).\n",
      " |        *args: additional positional arguments to be passed to `self.call`.\n",
      " |        **kwargs: additional keyword arguments to be passed to `self.call`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Output tensor(s).\n",
      " |  \n",
      " |  compute_mask(self, inputs, mask=None)\n",
      " |      Computes an output mask tensor.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          inputs: Tensor or list of tensors.\n",
      " |          mask: Tensor or list of tensors.\n",
      " |      \n",
      " |      Returns:\n",
      " |          None or a tensor (or list of tensors,\n",
      " |              one per output tensor of the layer).\n",
      " |  \n",
      " |  compute_output_signature(self, input_signature)\n",
      " |      Compute the output tensor signature of the layer based on the inputs.\n",
      " |      \n",
      " |      Unlike a TensorShape object, a TensorSpec object contains both shape\n",
      " |      and dtype information for a tensor. This method allows layers to provide\n",
      " |      output dtype information if it is different from the input dtype.\n",
      " |      For any layer that doesn't implement this function,\n",
      " |      the framework will fall back to use `compute_output_shape`, and will\n",
      " |      assume that the output dtype matches the input dtype.\n",
      " |      \n",
      " |      Args:\n",
      " |        input_signature: Single TensorSpec or nested structure of TensorSpec\n",
      " |          objects, describing a candidate input for the layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Single TensorSpec or nested structure of TensorSpec objects, describing\n",
      " |          how the layer would transform the provided input.\n",
      " |      \n",
      " |      Raises:\n",
      " |        TypeError: If input_signature contains a non-TensorSpec object.\n",
      " |  \n",
      " |  count_params(self)\n",
      " |      Count the total number of scalars composing the weights.\n",
      " |      \n",
      " |      Returns:\n",
      " |          An integer count.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: if the layer isn't yet built\n",
      " |            (in which case its weights aren't yet defined).\n",
      " |  \n",
      " |  get_input_at(self, node_index)\n",
      " |      Retrieves the input tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tensor (or list of tensors if the layer has multiple inputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_input_mask_at(self, node_index)\n",
      " |      Retrieves the input mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple inputs).\n",
      " |  \n",
      " |  get_input_shape_at(self, node_index)\n",
      " |      Retrieves the input shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple inputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_losses_for(self, inputs)\n",
      " |      Deprecated, do NOT use!\n",
      " |      \n",
      " |      Retrieves losses relevant to a specific set of inputs.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        inputs: Input tensor or list/tuple of input tensors.\n",
      " |      \n",
      " |      Returns:\n",
      " |        List of loss tensors of the layer that depend on `inputs`.\n",
      " |  \n",
      " |  get_output_at(self, node_index)\n",
      " |      Retrieves the output tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tensor (or list of tensors if the layer has multiple outputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_output_mask_at(self, node_index)\n",
      " |      Retrieves the output mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple outputs).\n",
      " |  \n",
      " |  get_output_shape_at(self, node_index)\n",
      " |      Retrieves the output shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple outputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_updates_for(self, inputs)\n",
      " |      Deprecated, do NOT use!\n",
      " |      \n",
      " |      Retrieves updates relevant to a specific set of inputs.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        inputs: Input tensor or list/tuple of input tensors.\n",
      " |      \n",
      " |      Returns:\n",
      " |        List of update ops of the layer that depend on `inputs`.\n",
      " |  \n",
      " |  get_weights(self)\n",
      " |      Returns the current weights of the layer.\n",
      " |      \n",
      " |      The weights of a layer represent the state of the layer. This function\n",
      " |      returns both trainable and non-trainable weight values associated with this\n",
      " |      layer as a list of Numpy arrays, which can in turn be used to load state\n",
      " |      into similarly parameterized layers.\n",
      " |      \n",
      " |      For example, a Dense layer returns a list of two values-- per-output\n",
      " |      weights and the bias value. These can be used to set the weights of another\n",
      " |      Dense layer:\n",
      " |      \n",
      " |      >>> a = tf.keras.layers.Dense(1,\n",
      " |      ...   kernel_initializer=tf.constant_initializer(1.))\n",
      " |      >>> a_out = a(tf.convert_to_tensor([[1., 2., 3.]]))\n",
      " |      >>> a.get_weights()\n",
      " |      [array([[1.],\n",
      " |             [1.],\n",
      " |             [1.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      >>> b = tf.keras.layers.Dense(1,\n",
      " |      ...   kernel_initializer=tf.constant_initializer(2.))\n",
      " |      >>> b_out = b(tf.convert_to_tensor([[10., 20., 30.]]))\n",
      " |      >>> b.get_weights()\n",
      " |      [array([[2.],\n",
      " |             [2.],\n",
      " |             [2.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      >>> b.set_weights(a.get_weights())\n",
      " |      >>> b.get_weights()\n",
      " |      [array([[1.],\n",
      " |             [1.],\n",
      " |             [1.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      \n",
      " |      Returns:\n",
      " |          Weights values as a list of numpy arrays.\n",
      " |  \n",
      " |  set_weights(self, weights)\n",
      " |      Sets the weights of the layer, from Numpy arrays.\n",
      " |      \n",
      " |      The weights of a layer represent the state of the layer. This function\n",
      " |      sets the weight values from numpy arrays. The weight values should be\n",
      " |      passed in the order they are created by the layer. Note that the layer's\n",
      " |      weights must be instantiated before calling this function by calling\n",
      " |      the layer.\n",
      " |      \n",
      " |      For example, a Dense layer returns a list of two values-- per-output\n",
      " |      weights and the bias value. These can be used to set the weights of another\n",
      " |      Dense layer:\n",
      " |      \n",
      " |      >>> a = tf.keras.layers.Dense(1,\n",
      " |      ...   kernel_initializer=tf.constant_initializer(1.))\n",
      " |      >>> a_out = a(tf.convert_to_tensor([[1., 2., 3.]]))\n",
      " |      >>> a.get_weights()\n",
      " |      [array([[1.],\n",
      " |             [1.],\n",
      " |             [1.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      >>> b = tf.keras.layers.Dense(1,\n",
      " |      ...   kernel_initializer=tf.constant_initializer(2.))\n",
      " |      >>> b_out = b(tf.convert_to_tensor([[10., 20., 30.]]))\n",
      " |      >>> b.get_weights()\n",
      " |      [array([[2.],\n",
      " |             [2.],\n",
      " |             [2.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      >>> b.set_weights(a.get_weights())\n",
      " |      >>> b.get_weights()\n",
      " |      [array([[1.],\n",
      " |             [1.],\n",
      " |             [1.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      \n",
      " |      Arguments:\n",
      " |          weights: a list of Numpy arrays. The number\n",
      " |              of arrays and their shape must match\n",
      " |              number of the dimensions of the weights\n",
      " |              of the layer (i.e. it should match the\n",
      " |              output of `get_weights`).\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: If the provided weights list does not match the\n",
      " |              layer's specifications.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from tensorflow.python.keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  from_config(config) from builtins.type\n",
      " |      Creates a layer from its config.\n",
      " |      \n",
      " |      This method is the reverse of `get_config`,\n",
      " |      capable of instantiating the same layer from the config\n",
      " |      dictionary. It does not handle layer connectivity\n",
      " |      (handled by Network), nor weights (handled by `set_weights`).\n",
      " |      \n",
      " |      Arguments:\n",
      " |          config: A Python dictionary, typically the\n",
      " |              output of get_config.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A layer instance.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  activity_regularizer\n",
      " |      Optional regularizer function for the output of this layer.\n",
      " |  \n",
      " |  compute_dtype\n",
      " |      The dtype of the layer's computations.\n",
      " |      \n",
      " |      This is equivalent to `Layer.dtype_policy.compute_dtype`. Unless\n",
      " |      mixed precision is used, this is the same as `Layer.dtype`, the dtype of\n",
      " |      the weights.\n",
      " |      \n",
      " |      Layers automatically cast their inputs to the compute dtype, which causes\n",
      " |      computations and the output to be in the compute dtype as well. This is done\n",
      " |      by the base Layer class in `Layer.__call__`, so you do not have to insert\n",
      " |      these casts if implementing your own layer.\n",
      " |      \n",
      " |      Layers often perform certain internal computations in higher precision when\n",
      " |      `compute_dtype` is float16 or bfloat16 for numeric stability. The output\n",
      " |      will still typically be float16 or bfloat16 in such cases.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The layer's compute dtype.\n",
      " |  \n",
      " |  dtype\n",
      " |      The dtype of the layer weights.\n",
      " |      \n",
      " |      This is equivalent to `Layer.dtype_policy.variable_dtype`. Unless\n",
      " |      mixed precision is used, this is the same as `Layer.compute_dtype`, the\n",
      " |      dtype of the layer's computations.\n",
      " |  \n",
      " |  dtype_policy\n",
      " |      The dtype policy associated with this layer.\n",
      " |      \n",
      " |      This is an instance of a `tf.keras.mixed_precision.Policy`.\n",
      " |  \n",
      " |  dynamic\n",
      " |      Whether the layer is dynamic (eager-only); set in the constructor.\n",
      " |  \n",
      " |  inbound_nodes\n",
      " |      Deprecated, do NOT use! Only for compatibility with external Keras.\n",
      " |  \n",
      " |  input\n",
      " |      Retrieves the input tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one input,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input tensor or list of input tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |        AttributeError: If no inbound nodes are found.\n",
      " |  \n",
      " |  input_mask\n",
      " |      Retrieves the input mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input mask tensor (potentially None) or list of input\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  input_shape\n",
      " |      Retrieves the input shape(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one input,\n",
      " |      i.e. if it is connected to one incoming layer, or if all inputs\n",
      " |      have the same shape.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input shape, as an integer shape tuple\n",
      " |          (or list of shape tuples, one tuple per input tensor).\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer has no defined input_shape.\n",
      " |          RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  input_spec\n",
      " |      `InputSpec` instance(s) describing the input format for this layer.\n",
      " |      \n",
      " |      When you create a layer subclass, you can set `self.input_spec` to enable\n",
      " |      the layer to run input compatibility checks when it is called.\n",
      " |      Consider a `Conv2D` layer: it can only be called on a single input tensor\n",
      " |      of rank 4. As such, you can set, in `__init__()`:\n",
      " |      \n",
      " |      ```python\n",
      " |      self.input_spec = tf.keras.layers.InputSpec(ndim=4)\n",
      " |      ```\n",
      " |      \n",
      " |      Now, if you try to call the layer on an input that isn't rank 4\n",
      " |      (for instance, an input of shape `(2,)`, it will raise a nicely-formatted\n",
      " |      error:\n",
      " |      \n",
      " |      ```\n",
      " |      ValueError: Input 0 of layer conv2d is incompatible with the layer:\n",
      " |      expected ndim=4, found ndim=1. Full shape received: [2]\n",
      " |      ```\n",
      " |      \n",
      " |      Input checks that can be specified via `input_spec` include:\n",
      " |      - Structure (e.g. a single input, a list of 2 inputs, etc)\n",
      " |      - Shape\n",
      " |      - Rank (ndim)\n",
      " |      - Dtype\n",
      " |      \n",
      " |      For more information, see `tf.keras.layers.InputSpec`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A `tf.keras.layers.InputSpec` instance, or nested structure thereof.\n",
      " |  \n",
      " |  losses\n",
      " |      List of losses added using the `add_loss()` API.\n",
      " |      \n",
      " |      Variable regularization tensors are created when this property is accessed,\n",
      " |      so it is eager safe: accessing `losses` under a `tf.GradientTape` will\n",
      " |      propagate gradients back to the corresponding variables.\n",
      " |      \n",
      " |      Examples:\n",
      " |      \n",
      " |      >>> class MyLayer(tf.keras.layers.Layer):\n",
      " |      ...   def call(self, inputs):\n",
      " |      ...     self.add_loss(tf.abs(tf.reduce_mean(inputs)))\n",
      " |      ...     return inputs\n",
      " |      >>> l = MyLayer()\n",
      " |      >>> l(np.ones((10, 1)))\n",
      " |      >>> l.losses\n",
      " |      [1.0]\n",
      " |      \n",
      " |      >>> inputs = tf.keras.Input(shape=(10,))\n",
      " |      >>> x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      >>> outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      >>> model = tf.keras.Model(inputs, outputs)\n",
      " |      >>> # Activity regularization.\n",
      " |      >>> len(model.losses)\n",
      " |      0\n",
      " |      >>> model.add_loss(tf.abs(tf.reduce_mean(x)))\n",
      " |      >>> len(model.losses)\n",
      " |      1\n",
      " |      \n",
      " |      >>> inputs = tf.keras.Input(shape=(10,))\n",
      " |      >>> d = tf.keras.layers.Dense(10, kernel_initializer='ones')\n",
      " |      >>> x = d(inputs)\n",
      " |      >>> outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      >>> model = tf.keras.Model(inputs, outputs)\n",
      " |      >>> # Weight regularization.\n",
      " |      >>> model.add_loss(lambda: tf.reduce_mean(d.kernel))\n",
      " |      >>> model.losses\n",
      " |      [<tf.Tensor: shape=(), dtype=float32, numpy=1.0>]\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of tensors.\n",
      " |  \n",
      " |  metrics\n",
      " |      List of metrics added using the `add_metric()` API.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      >>> input = tf.keras.layers.Input(shape=(3,))\n",
      " |      >>> d = tf.keras.layers.Dense(2)\n",
      " |      >>> output = d(input)\n",
      " |      >>> d.add_metric(tf.reduce_max(output), name='max')\n",
      " |      >>> d.add_metric(tf.reduce_min(output), name='min')\n",
      " |      >>> [m.name for m in d.metrics]\n",
      " |      ['max', 'min']\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of `Metric` objects.\n",
      " |  \n",
      " |  name\n",
      " |      Name of the layer (string), set in the constructor.\n",
      " |  \n",
      " |  non_trainable_variables\n",
      " |  \n",
      " |  non_trainable_weights\n",
      " |      List of all non-trainable weights tracked by this layer.\n",
      " |      \n",
      " |      Non-trainable weights are *not* updated during training. They are expected\n",
      " |      to be updated manually in `call()`.\n",
      " |      \n",
      " |      Note: This will not track the weights of nested `tf.Modules` that are not\n",
      " |      themselves Keras layers.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of non-trainable variables.\n",
      " |  \n",
      " |  outbound_nodes\n",
      " |      Deprecated, do NOT use! Only for compatibility with external Keras.\n",
      " |  \n",
      " |  output\n",
      " |      Retrieves the output tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one output,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Output tensor or list of output tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |        AttributeError: if the layer is connected to more than one incoming\n",
      " |          layers.\n",
      " |        RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  output_mask\n",
      " |      Retrieves the output mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Output mask tensor (potentially None) or list of output\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  output_shape\n",
      " |      Retrieves the output shape(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has one output,\n",
      " |      or if all outputs have the same shape.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Output shape, as an integer shape tuple\n",
      " |          (or list of shape tuples, one tuple per output tensor).\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer has no defined output shape.\n",
      " |          RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  stateful\n",
      " |  \n",
      " |  supports_masking\n",
      " |      Whether this layer supports computing a mask using `compute_mask`.\n",
      " |  \n",
      " |  trainable\n",
      " |  \n",
      " |  trainable_variables\n",
      " |      Sequence of trainable variables owned by this module and its submodules.\n",
      " |      \n",
      " |      Note: this method uses reflection to find variables on the current instance\n",
      " |      and submodules. For performance reasons you may wish to cache the result\n",
      " |      of calling this method if you don't expect the return value to change.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of variables for the current module (sorted by attribute\n",
      " |        name) followed by variables from all submodules recursively (breadth\n",
      " |        first).\n",
      " |  \n",
      " |  trainable_weights\n",
      " |      List of all trainable weights tracked by this layer.\n",
      " |      \n",
      " |      Trainable weights are updated via gradient descent during training.\n",
      " |      \n",
      " |      Note: This will not track the weights of nested `tf.Modules` that are not\n",
      " |      themselves Keras layers.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of trainable variables.\n",
      " |  \n",
      " |  updates\n",
      " |  \n",
      " |  variable_dtype\n",
      " |      Alias of `Layer.dtype`, the dtype of the weights.\n",
      " |  \n",
      " |  variables\n",
      " |      Returns the list of all layer variables/weights.\n",
      " |      \n",
      " |      Alias of `self.weights`.\n",
      " |      \n",
      " |      Note: This will not track the weights of nested `tf.Modules` that are not\n",
      " |      themselves Keras layers.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of variables.\n",
      " |  \n",
      " |  weights\n",
      " |      Returns the list of all layer variables/weights.\n",
      " |      \n",
      " |      Note: This will not track the weights of nested `tf.Modules` that are not\n",
      " |      themselves Keras layers.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of variables.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from tensorflow.python.module.module.Module:\n",
      " |  \n",
      " |  with_name_scope(method) from builtins.type\n",
      " |      Decorator to automatically enter the module name scope.\n",
      " |      \n",
      " |      >>> class MyModule(tf.Module):\n",
      " |      ...   @tf.Module.with_name_scope\n",
      " |      ...   def __call__(self, x):\n",
      " |      ...     if not hasattr(self, 'w'):\n",
      " |      ...       self.w = tf.Variable(tf.random.normal([x.shape[1], 3]))\n",
      " |      ...     return tf.matmul(x, self.w)\n",
      " |      \n",
      " |      Using the above module would produce `tf.Variable`s and `tf.Tensor`s whose\n",
      " |      names included the module name:\n",
      " |      \n",
      " |      >>> mod = MyModule()\n",
      " |      >>> mod(tf.ones([1, 2]))\n",
      " |      <tf.Tensor: shape=(1, 3), dtype=float32, numpy=..., dtype=float32)>\n",
      " |      >>> mod.w\n",
      " |      <tf.Variable 'my_module/Variable:0' shape=(2, 3) dtype=float32,\n",
      " |      numpy=..., dtype=float32)>\n",
      " |      \n",
      " |      Args:\n",
      " |        method: The method to wrap.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The original method wrapped such that it enters the module's name scope.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.module.module.Module:\n",
      " |  \n",
      " |  name_scope\n",
      " |      Returns a `tf.name_scope` instance for this class.\n",
      " |  \n",
      " |  submodules\n",
      " |      Sequence of all sub-modules.\n",
      " |      \n",
      " |      Submodules are modules which are properties of this module, or found as\n",
      " |      properties of modules which are properties of this module (and so on).\n",
      " |      \n",
      " |      >>> a = tf.Module()\n",
      " |      >>> b = tf.Module()\n",
      " |      >>> c = tf.Module()\n",
      " |      >>> a.b = b\n",
      " |      >>> b.c = c\n",
      " |      >>> list(a.submodules) == [b, c]\n",
      " |      True\n",
      " |      >>> list(b.submodules) == [c]\n",
      " |      True\n",
      " |      >>> list(c.submodules) == []\n",
      " |      True\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of all submodules.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.training.tracking.base.Trackable:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods inherited from tensorflow.python.keras.utils.version_utils.LayerVersionSelector:\n",
      " |  \n",
      " |  __new__(cls, *args, **kwargs)\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(Dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "billion-alloy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential([Dense(4,activation='relu'),\n",
    "#                     Dense(2,activation='relu'),\n",
    "#                     Dense(1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dense-coordination",
   "metadata": {},
   "outputs": [],
   "source": [
    "#more modular additions to model layers same as above\n",
    "model = Sequential()\n",
    "\n",
    "#layers\n",
    "model.add(Dense(4,activation='relu'))\n",
    "model.add(Dense(4,activation='relu'))\n",
    "model.add(Dense(4,activation='relu'))\n",
    "#output layer - single neuron to produce price prediction\n",
    "model.add(Dense(1))\n",
    "# add loss function to model\n",
    "model.compile(optimizer='rmsprop',loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "equipped-witch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "22/22 [==============================] - 1s 2ms/step - loss: 255709.5584\n",
      "Epoch 2/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 253119.7887\n",
      "Epoch 3/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 253999.5353\n",
      "Epoch 4/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 262840.8560\n",
      "Epoch 5/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 261281.1855\n",
      "Epoch 6/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 256296.2629\n",
      "Epoch 7/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 261801.3037\n",
      "Epoch 8/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 258386.7004\n",
      "Epoch 9/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 257640.6705\n",
      "Epoch 10/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 255859.2432\n",
      "Epoch 11/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 252290.8818\n",
      "Epoch 12/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 253939.6325\n",
      "Epoch 13/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 249674.9728\n",
      "Epoch 14/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 250892.9049\n",
      "Epoch 15/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 252114.3533\n",
      "Epoch 16/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 256606.3872\n",
      "Epoch 17/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 255633.4307\n",
      "Epoch 18/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 254038.9939\n",
      "Epoch 19/250\n",
      "22/22 [==============================] - ETA: 0s - loss: 248586.51 - 0s 2ms/step - loss: 251168.6766\n",
      "Epoch 20/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 249498.3764\n",
      "Epoch 21/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 251731.8804\n",
      "Epoch 22/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 252440.5333\n",
      "Epoch 23/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 249747.3974\n",
      "Epoch 24/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 255743.9232\n",
      "Epoch 25/250\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 249155.3186\n",
      "Epoch 26/250\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 252653.0312\n",
      "Epoch 27/250\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 246258.2704\n",
      "Epoch 28/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 254034.9327\n",
      "Epoch 29/250\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 246308.1970\n",
      "Epoch 30/250\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 253736.8770\n",
      "Epoch 31/250\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 241335.4416\n",
      "Epoch 32/250\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 243412.6576\n",
      "Epoch 33/250\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 247873.8777\n",
      "Epoch 34/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 244315.9742: 0s - loss: 244773.61\n",
      "Epoch 35/250\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 241841.8390\n",
      "Epoch 36/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 244187.0611\n",
      "Epoch 37/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 234440.2711\n",
      "Epoch 38/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 235433.9130\n",
      "Epoch 39/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 231200.2962\n",
      "Epoch 40/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 233509.4857\n",
      "Epoch 41/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 229038.6855\n",
      "Epoch 42/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 226077.1909\n",
      "Epoch 43/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 227368.0136\n",
      "Epoch 44/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 223329.6895\n",
      "Epoch 45/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 220219.7154\n",
      "Epoch 46/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 223678.7459\n",
      "Epoch 47/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 218322.2058\n",
      "Epoch 48/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 214538.7391\n",
      "Epoch 49/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 215999.2812\n",
      "Epoch 50/250\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 207305.0740\n",
      "Epoch 51/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 207073.3696\n",
      "Epoch 52/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 199244.1488\n",
      "Epoch 53/250\n",
      "22/22 [==============================] - ETA: 0s - loss: 191606.62 - 0s 1ms/step - loss: 198267.5143\n",
      "Epoch 54/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 194903.8539\n",
      "Epoch 55/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 188669.1359\n",
      "Epoch 56/250\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 187188.8152\n",
      "Epoch 57/250\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 181426.4022\n",
      "Epoch 58/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 177140.5401\n",
      "Epoch 59/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 171353.5034\n",
      "Epoch 60/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 168060.9980\n",
      "Epoch 61/250\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 163860.0971\n",
      "Epoch 62/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 158015.9341\n",
      "Epoch 63/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 149733.8533\n",
      "Epoch 64/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 146140.2894\n",
      "Epoch 65/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 140548.0632\n",
      "Epoch 66/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 133782.9925\n",
      "Epoch 67/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 129474.7116\n",
      "Epoch 68/250\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 122323.9616\n",
      "Epoch 69/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 118977.9117\n",
      "Epoch 70/250\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 110280.3295\n",
      "Epoch 71/250\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 106216.1444\n",
      "Epoch 72/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 98981.4976\n",
      "Epoch 73/250\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 95492.4273\n",
      "Epoch 74/250\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 86673.7306\n",
      "Epoch 75/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 81053.5788\n",
      "Epoch 76/250\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 74546.0190\n",
      "Epoch 77/250\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 70460.9409\n",
      "Epoch 78/250\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 64232.4387\n",
      "Epoch 79/250\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 55310.2413\n",
      "Epoch 80/250\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 51103.2880\n",
      "Epoch 81/250\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 45290.9037\n",
      "Epoch 82/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 40691.3375\n",
      "Epoch 83/250\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 32319.0902\n",
      "Epoch 84/250\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 28469.2374\n",
      "Epoch 85/250\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 25292.3554\n",
      "Epoch 86/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 20911.8854\n",
      "Epoch 87/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 15423.7959\n",
      "Epoch 88/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 12488.3779\n",
      "Epoch 89/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 9045.5587\n",
      "Epoch 90/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 6411.4371\n",
      "Epoch 91/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 5079.0113\n",
      "Epoch 92/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 3265.9243\n",
      "Epoch 93/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 2593.0196\n",
      "Epoch 94/250\n",
      "22/22 [==============================] - ETA: 0s - loss: 3146.29 - 0s 2ms/step - loss: 2407.5804\n",
      "Epoch 95/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 2289.5514\n",
      "Epoch 96/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1974.0531\n",
      "Epoch 97/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 2157.2328\n",
      "Epoch 98/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 2056.5076\n",
      "Epoch 99/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1875.5482\n",
      "Epoch 100/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 2002.3040\n",
      "Epoch 101/250\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 2191.5223\n",
      "Epoch 102/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1882.0713\n",
      "Epoch 103/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1847.5043\n",
      "Epoch 104/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1878.4140\n",
      "Epoch 105/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1918.3886\n",
      "Epoch 106/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1804.1141\n",
      "Epoch 107/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1909.1473\n",
      "Epoch 108/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1874.3118\n",
      "Epoch 109/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1657.7543\n",
      "Epoch 110/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1680.3441\n",
      "Epoch 111/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1711.8330\n",
      "Epoch 112/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1733.9245\n",
      "Epoch 113/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1509.4801\n",
      "Epoch 114/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1658.1822\n",
      "Epoch 115/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1471.8363\n",
      "Epoch 116/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1576.6132\n",
      "Epoch 117/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1479.6316\n",
      "Epoch 118/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1571.9553\n",
      "Epoch 119/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1565.5857\n",
      "Epoch 120/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1388.7623\n",
      "Epoch 121/250\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 1224.9426\n",
      "Epoch 122/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1350.6003\n",
      "Epoch 123/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1175.1245\n",
      "Epoch 124/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1337.4400\n",
      "Epoch 125/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1151.9547\n",
      "Epoch 126/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1147.3495\n",
      "Epoch 127/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1133.0529\n",
      "Epoch 128/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1081.1572\n",
      "Epoch 129/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1126.5947\n",
      "Epoch 130/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1070.2773\n",
      "Epoch 131/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1013.9916\n",
      "Epoch 132/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1055.1907\n",
      "Epoch 133/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 920.7182\n",
      "Epoch 134/250\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 1008.3976\n",
      "Epoch 135/250\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 1003.6598\n",
      "Epoch 136/250\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 866.6022\n",
      "Epoch 137/250\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 907.1883\n",
      "Epoch 138/250\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 855.7102\n",
      "Epoch 139/250\n",
      "22/22 [==============================] - 0s 957us/step - loss: 790.6147\n",
      "Epoch 140/250\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 807.9822\n",
      "Epoch 141/250\n",
      "22/22 [==============================] - 0s 936us/step - loss: 779.1898\n",
      "Epoch 142/250\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 782.9116\n",
      "Epoch 143/250\n",
      "22/22 [==============================] - 0s 936us/step - loss: 705.6673\n",
      "Epoch 144/250\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 695.0796\n",
      "Epoch 145/250\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 716.0305\n",
      "Epoch 146/250\n",
      "22/22 [==============================] - 0s 958us/step - loss: 631.3416\n",
      "Epoch 147/250\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 629.7982\n",
      "Epoch 148/250\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 599.1456\n",
      "Epoch 149/250\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 565.4498\n",
      "Epoch 150/250\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 568.3748\n",
      "Epoch 151/250\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 546.6459\n",
      "Epoch 152/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 498.3491\n",
      "Epoch 153/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 494.7239\n",
      "Epoch 154/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 490.5847\n",
      "Epoch 155/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 461.7292\n",
      "Epoch 156/250\n",
      "22/22 [==============================] - ETA: 0s - loss: 488.000 - 0s 2ms/step - loss: 436.3632\n",
      "Epoch 157/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 440.1879\n",
      "Epoch 158/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 421.4170\n",
      "Epoch 159/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 414.4793\n",
      "Epoch 160/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 372.5705\n",
      "Epoch 161/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 379.2239\n",
      "Epoch 162/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 323.0285\n",
      "Epoch 163/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 323.7775\n",
      "Epoch 164/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 288.2696\n",
      "Epoch 165/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 311.7725\n",
      "Epoch 166/250\n",
      "22/22 [==============================] - 0s 959us/step - loss: 272.3532\n",
      "Epoch 167/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 274.0262\n",
      "Epoch 168/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 264.8727\n",
      "Epoch 169/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 219.3934\n",
      "Epoch 170/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 199.1252\n",
      "Epoch 171/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 209.1128\n",
      "Epoch 172/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 185.0610\n",
      "Epoch 173/250\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 173.9946\n",
      "Epoch 174/250\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 164.0844\n",
      "Epoch 175/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 149.5164\n",
      "Epoch 176/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 136.2160\n",
      "Epoch 177/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 139.2612\n",
      "Epoch 178/250\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 122.1549\n",
      "Epoch 179/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 106.8354\n",
      "Epoch 180/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 96.6303\n",
      "Epoch 181/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 89.7619\n",
      "Epoch 182/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 95.5745\n",
      "Epoch 183/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 82.0949\n",
      "Epoch 184/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 78.3288\n",
      "Epoch 185/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 73.0683\n",
      "Epoch 186/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 72.2222\n",
      "Epoch 187/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 61.4985\n",
      "Epoch 188/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 58.5961\n",
      "Epoch 189/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 53.1311\n",
      "Epoch 190/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 49.1740\n",
      "Epoch 191/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 46.6354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 192/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 42.2872\n",
      "Epoch 193/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 38.9124\n",
      "Epoch 194/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 37.8565\n",
      "Epoch 195/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 35.4542\n",
      "Epoch 196/250\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 35.2846\n",
      "Epoch 197/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 31.9171\n",
      "Epoch 198/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 30.8448\n",
      "Epoch 199/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 30.8200\n",
      "Epoch 200/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 28.5439\n",
      "Epoch 201/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 28.7529\n",
      "Epoch 202/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 26.5496\n",
      "Epoch 203/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 28.3279\n",
      "Epoch 204/250\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 24.3939\n",
      "Epoch 205/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 26.2412\n",
      "Epoch 206/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 26.2461\n",
      "Epoch 207/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 26.7893\n",
      "Epoch 208/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 27.6077\n",
      "Epoch 209/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 26.0688\n",
      "Epoch 210/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 25.5929\n",
      "Epoch 211/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 24.8172\n",
      "Epoch 212/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 23.1204\n",
      "Epoch 213/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 24.4388\n",
      "Epoch 214/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 23.8579\n",
      "Epoch 215/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 25.0098\n",
      "Epoch 216/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 25.1971\n",
      "Epoch 217/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 25.4986\n",
      "Epoch 218/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 22.5462\n",
      "Epoch 219/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 23.8386\n",
      "Epoch 220/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 23.7042\n",
      "Epoch 221/250\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 24.9832\n",
      "Epoch 222/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 25.1998\n",
      "Epoch 223/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 23.1834\n",
      "Epoch 224/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 25.2991\n",
      "Epoch 225/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 26.3572\n",
      "Epoch 226/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 23.9521\n",
      "Epoch 227/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 22.6894\n",
      "Epoch 228/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 26.5027\n",
      "Epoch 229/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 22.5977\n",
      "Epoch 230/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 23.2859\n",
      "Epoch 231/250\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 24.3942\n",
      "Epoch 232/250\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 24.2538\n",
      "Epoch 233/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 23.2150\n",
      "Epoch 234/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 23.2192\n",
      "Epoch 235/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 26.1687\n",
      "Epoch 236/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 25.0188\n",
      "Epoch 237/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 24.7243\n",
      "Epoch 238/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 25.6791\n",
      "Epoch 239/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 23.7324\n",
      "Epoch 240/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 23.4548\n",
      "Epoch 241/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 22.4644\n",
      "Epoch 242/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 23.3537\n",
      "Epoch 243/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 23.4477\n",
      "Epoch 244/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 23.7949\n",
      "Epoch 245/250\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 23.8084\n",
      "Epoch 246/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 23.3710\n",
      "Epoch 247/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 23.2538\n",
      "Epoch 248/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 24.2637\n",
      "Epoch 249/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 26.5513\n",
      "Epoch 250/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 24.2957\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x21f2649a630>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#extremely basic fit\n",
    "model.fit(x=X_train,y=y_train,epochs=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "collect-character",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_df = pd.DataFrame(model.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "charming-pennsylvania",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x21f26b3f240>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_df.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "divine-monday",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27.79046630859375"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluating prediction of test data\n",
    "model.evaluate(X_test,y_test,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "unnecessary-paris",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.265155792236328"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_train,y_train,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "expanded-bahamas",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "handmade-edmonton",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[406.55127],\n",
       "       [625.46014],\n",
       "       [593.9669 ],\n",
       "       [573.97034],\n",
       "       [367.7202 ],\n",
       "       [580.9598 ],\n",
       "       [516.6058 ],\n",
       "       [460.54794],\n",
       "       [550.9207 ],\n",
       "       [448.92838],\n",
       "       [613.672  ],\n",
       "       [550.6819 ],\n",
       "       [420.40012],\n",
       "       [410.13263],\n",
       "       [653.28906],\n",
       "       [438.66922],\n",
       "       [510.05948],\n",
       "       [661.92706],\n",
       "       [664.6071 ],\n",
       "       [567.2995 ],\n",
       "       [335.25357],\n",
       "       [446.2124 ],\n",
       "       [383.7038 ],\n",
       "       [379.9384 ],\n",
       "       [568.3411 ],\n",
       "       [612.45233],\n",
       "       [534.0303 ],\n",
       "       [429.19403],\n",
       "       [657.43713],\n",
       "       [415.38593],\n",
       "       [444.02658],\n",
       "       [486.631  ],\n",
       "       [439.7793 ],\n",
       "       [683.92664],\n",
       "       [426.10526],\n",
       "       [418.96805],\n",
       "       [503.52502],\n",
       "       [552.1791 ],\n",
       "       [511.27905],\n",
       "       [396.54996],\n",
       "       [620.5063 ],\n",
       "       [417.93646],\n",
       "       [606.32025],\n",
       "       [447.37378],\n",
       "       [503.54227],\n",
       "       [583.5553 ],\n",
       "       [671.0924 ],\n",
       "       [491.93784],\n",
       "       [319.5976 ],\n",
       "       [486.9273 ],\n",
       "       [518.8712 ],\n",
       "       [383.00195],\n",
       "       [543.614  ],\n",
       "       [409.86823],\n",
       "       [643.5062 ],\n",
       "       [492.59097],\n",
       "       [629.8472 ],\n",
       "       [628.9673 ],\n",
       "       [448.4621 ],\n",
       "       [486.1868 ],\n",
       "       [492.64377],\n",
       "       [476.023  ],\n",
       "       [684.89655],\n",
       "       [404.53198],\n",
       "       [703.2952 ],\n",
       "       [588.19824],\n",
       "       [584.92615],\n",
       "       [539.53577],\n",
       "       [486.07666],\n",
       "       [518.1418 ],\n",
       "       [362.35904],\n",
       "       [542.42786],\n",
       "       [572.38226],\n",
       "       [530.1317 ],\n",
       "       [455.13815],\n",
       "       [532.79614],\n",
       "       [508.80377],\n",
       "       [444.6937 ],\n",
       "       [545.04126],\n",
       "       [642.7548 ],\n",
       "       [467.42307],\n",
       "       [569.022  ],\n",
       "       [692.9189 ],\n",
       "       [460.1492 ],\n",
       "       [711.0719 ],\n",
       "       [474.1616 ],\n",
       "       [404.5642 ],\n",
       "       [586.90784],\n",
       "       [438.1453 ],\n",
       "       [490.49457],\n",
       "       [618.9489 ],\n",
       "       [440.8622 ],\n",
       "       [456.7242 ],\n",
       "       [436.6077 ],\n",
       "       [508.46188],\n",
       "       [610.3169 ],\n",
       "       [322.6381 ],\n",
       "       [437.63846],\n",
       "       [538.0123 ],\n",
       "       [520.2256 ],\n",
       "       [606.89716],\n",
       "       [527.0684 ],\n",
       "       [335.20496],\n",
       "       [577.97205],\n",
       "       [433.0908 ],\n",
       "       [564.333  ],\n",
       "       [515.0015 ],\n",
       "       [392.2954 ],\n",
       "       [567.9692 ],\n",
       "       [456.24634],\n",
       "       [449.87042],\n",
       "       [642.9417 ],\n",
       "       [526.021  ],\n",
       "       [552.4101 ],\n",
       "       [418.99487],\n",
       "       [480.22226],\n",
       "       [588.3367 ],\n",
       "       [669.4176 ],\n",
       "       [702.60474],\n",
       "       [661.3915 ],\n",
       "       [562.3005 ],\n",
       "       [504.75308],\n",
       "       [391.55252],\n",
       "       [282.22168],\n",
       "       [481.11386],\n",
       "       [618.2997 ],\n",
       "       [374.50757],\n",
       "       [513.85254],\n",
       "       [512.5862 ],\n",
       "       [495.00543],\n",
       "       [481.9548 ],\n",
       "       [425.0881 ],\n",
       "       [494.98337],\n",
       "       [472.94144],\n",
       "       [602.3306 ],\n",
       "       [575.39215],\n",
       "       [416.2302 ],\n",
       "       [632.60114],\n",
       "       [467.836  ],\n",
       "       [566.1003 ],\n",
       "       [406.95218],\n",
       "       [533.8229 ],\n",
       "       [574.40656],\n",
       "       [358.18604],\n",
       "       [551.5307 ],\n",
       "       [605.2212 ],\n",
       "       [385.4977 ],\n",
       "       [544.0577 ],\n",
       "       [564.3399 ],\n",
       "       [454.31458],\n",
       "       [634.1615 ],\n",
       "       [373.39383],\n",
       "       [475.71262],\n",
       "       [530.4875 ],\n",
       "       [373.4778 ],\n",
       "       [462.65604],\n",
       "       [437.6549 ],\n",
       "       [500.04156],\n",
       "       [347.2233 ],\n",
       "       [396.54202],\n",
       "       [606.4631 ],\n",
       "       [508.237  ],\n",
       "       [470.06873],\n",
       "       [491.90683],\n",
       "       [536.96796],\n",
       "       [345.5747 ],\n",
       "       [513.95996],\n",
       "       [251.61194],\n",
       "       [505.65564],\n",
       "       [542.7513 ],\n",
       "       [490.88815],\n",
       "       [472.59122],\n",
       "       [393.7806 ],\n",
       "       [417.5866 ],\n",
       "       [551.2735 ],\n",
       "       [477.2548 ],\n",
       "       [581.7268 ],\n",
       "       [491.27234],\n",
       "       [602.81586],\n",
       "       [548.71   ],\n",
       "       [543.6569 ],\n",
       "       [502.14154],\n",
       "       [647.82654],\n",
       "       [562.1495 ],\n",
       "       [579.76434],\n",
       "       [445.5445 ],\n",
       "       [416.83914],\n",
       "       [421.32767],\n",
       "       [570.9061 ],\n",
       "       [610.88745],\n",
       "       [439.13995],\n",
       "       [489.49814],\n",
       "       [589.5507 ],\n",
       "       [526.9981 ],\n",
       "       [358.47925],\n",
       "       [647.4024 ],\n",
       "       [529.65985],\n",
       "       [338.27408],\n",
       "       [494.22232],\n",
       "       [411.46008],\n",
       "       [608.4861 ],\n",
       "       [347.64584],\n",
       "       [524.06244],\n",
       "       [405.96692],\n",
       "       [259.20096],\n",
       "       [521.5255 ],\n",
       "       [342.0044 ],\n",
       "       [363.15906],\n",
       "       [578.23047],\n",
       "       [418.0002 ],\n",
       "       [552.6853 ],\n",
       "       [522.6929 ],\n",
       "       [512.298  ],\n",
       "       [325.78293],\n",
       "       [405.38696],\n",
       "       [604.248  ],\n",
       "       [619.7582 ],\n",
       "       [605.1005 ],\n",
       "       [568.0738 ],\n",
       "       [474.8825 ],\n",
       "       [461.80713],\n",
       "       [510.0087 ],\n",
       "       [447.31067],\n",
       "       [512.92957],\n",
       "       [503.91006],\n",
       "       [401.4023 ],\n",
       "       [607.4027 ],\n",
       "       [258.95203],\n",
       "       [630.2072 ],\n",
       "       [591.00146],\n",
       "       [328.19556],\n",
       "       [481.02267],\n",
       "       [597.1975 ],\n",
       "       [379.58817],\n",
       "       [461.5858 ],\n",
       "       [326.05386],\n",
       "       [520.32544],\n",
       "       [410.92664],\n",
       "       [557.98535],\n",
       "       [643.88666],\n",
       "       [538.48627],\n",
       "       [504.75534],\n",
       "       [637.0235 ],\n",
       "       [516.8549 ],\n",
       "       [533.3596 ],\n",
       "       [520.4185 ],\n",
       "       [458.87262],\n",
       "       [507.42175],\n",
       "       [462.5519 ],\n",
       "       [593.56635],\n",
       "       [467.35516],\n",
       "       [428.4987 ],\n",
       "       [543.25385],\n",
       "       [495.33267],\n",
       "       [681.7177 ],\n",
       "       [373.93326],\n",
       "       [553.3245 ],\n",
       "       [579.7602 ],\n",
       "       [435.30185],\n",
       "       [544.69916],\n",
       "       [587.84186],\n",
       "       [581.0663 ],\n",
       "       [723.16205],\n",
       "       [434.06332],\n",
       "       [399.85388],\n",
       "       [315.01035],\n",
       "       [449.6679 ],\n",
       "       [389.33304],\n",
       "       [544.8755 ],\n",
       "       [524.3533 ],\n",
       "       [566.2726 ],\n",
       "       [449.41306],\n",
       "       [536.0781 ],\n",
       "       [382.9918 ],\n",
       "       [503.08023],\n",
       "       [639.0603 ],\n",
       "       [498.12375],\n",
       "       [570.1399 ],\n",
       "       [471.5608 ],\n",
       "       [274.21356],\n",
       "       [518.95605],\n",
       "       [623.31683],\n",
       "       [351.61255],\n",
       "       [451.82178],\n",
       "       [500.8274 ],\n",
       "       [544.6572 ],\n",
       "       [613.73566],\n",
       "       [389.36102],\n",
       "       [450.76935],\n",
       "       [483.92273],\n",
       "       [600.1587 ],\n",
       "       [500.90588],\n",
       "       [322.47   ],\n",
       "       [556.8651 ],\n",
       "       [446.0194 ],\n",
       "       [530.66187],\n",
       "       [516.8582 ],\n",
       "       [611.535  ],\n",
       "       [418.27112],\n",
       "       [412.13846]], dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "quiet-science",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prediction = pd.Series(test_predictions.reshape(300,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "frank-commission",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame(y_test,columns=['Test True Y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "contemporary-honor",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.concat([pred_df,test_prediction],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "early-burton",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.columns = ['Test True Y','Model Predictions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bridal-mobile",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x21f27e11438>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.scatterplot(data=pred_df,x='Test True Y',y='Model Predictions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "caring-session",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error,mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "afraid-cover",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.279917834586663"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(pred_df['Test True Y'],pred_df['Model Predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "coordinated-helena",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>498.673029</td>\n",
       "      <td>1000.014171</td>\n",
       "      <td>999.979847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>93.785431</td>\n",
       "      <td>0.974018</td>\n",
       "      <td>0.948330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>223.346793</td>\n",
       "      <td>997.058347</td>\n",
       "      <td>996.995651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>433.025732</td>\n",
       "      <td>999.332068</td>\n",
       "      <td>999.316106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>502.382117</td>\n",
       "      <td>1000.009915</td>\n",
       "      <td>1000.002243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>564.921588</td>\n",
       "      <td>1000.637580</td>\n",
       "      <td>1000.645380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>774.407854</td>\n",
       "      <td>1003.207934</td>\n",
       "      <td>1002.666308</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             price     feature1     feature2\n",
       "count  1000.000000  1000.000000  1000.000000\n",
       "mean    498.673029  1000.014171   999.979847\n",
       "std      93.785431     0.974018     0.948330\n",
       "min     223.346793   997.058347   996.995651\n",
       "25%     433.025732   999.332068   999.316106\n",
       "50%     502.382117  1000.009915  1000.002243\n",
       "75%     564.921588  1000.637580  1000.645380\n",
       "max     774.407854  1003.207934  1002.666308"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "decimal-green",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.271666516441955"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#practically same as our loss\n",
    "mean_squared_error(pred_df['Test True Y'],pred_df['Model Predictions'])**.5 #**.5 root mean squared error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tired-albert",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting on a new input!!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "devoted-times",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_gem = [[998,1000]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "foster-white",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_gem = scaler.transform(new_gem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "twenty-novel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[420.95346]], dtype=float32)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(new_gem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "standard-spencer",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving a model to use later!!!!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "yellow-tongue",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "tested-moore",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('my_gem_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "right-browser",
   "metadata": {},
   "outputs": [],
   "source": [
    "later_model = load_model('my_gem_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "responsible-scene",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[420.95346]], dtype=float32)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "later_model.predict(new_gem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "republican-chancellor",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
